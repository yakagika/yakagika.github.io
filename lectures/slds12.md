---
title: 特別講義DS Ch12 一般化線形モデル
description: 資料
tags:
    - datascience
    - statistics
    - python
featured: true
date: 2025-11-04
tableOfContents: true
previousChapter: slds11.html
nextChapter: slds13.html
---

# 統計モデリング


前回(Ch11)では線形の重回帰を利用して,ある程度正確な説明/予測が可能となりました.
しかし,これが最善のモデルであるとは限りません.
また, 線形回帰でうまく表せないからと言って,関係がないと断定することもできません.
より正確に説明できるより良いモデルが存在する可能性があります.

前回の事例に即して考えると例えば,

::: note

- Scholarshipの有無によって,それぞれの傾きが異なるのでは?

奨学金をもらっている人のほうがそもそも勉強時間あたりのGPAの伸び率が高いなど,層ごとに異なるパラメータを持つ可能性があります.

- 残差の分布が正規分布ではないのでは?

重回帰分析では残差が正規分布であるという仮定のもと分析を行っていますが,そのような検証は行われていません.

:::

基本的にはデータを特定のモデルで表現する場合には,グラフや特徴量などから考えられる幾つかの可能性を考慮・比較検討し,最善のモデルを選択することが必要になります.
このような行為をモデル選択/統計モデリングといいます.

Ch 12ではこのような,重回帰分析では扱えないモデリング技法として,ベイズ統計学に基づいた一般化線形モデルに関して学習してみましょう.


# 基礎知識 ベイズ統計学概要

前章までに扱ってきた,統計的仮説検定や回帰分析は無限回試行を行った際に収束する相対度数(**客観確率**)を確率の定義とする**頻度主義**に基づいた統計的手法です(詳細は｢統計学入門(データ活用の統計学)｣などに譲ります.) そのような前提にたった統計学を**伝統的統計学**とも呼びます.

一方で,2000年代初頭から,計算機の性能向上と,MCMCなどのアルゴリズムの開発によって,分析者の情報,知識,経験などによる主観によって定めらる**主観確率**に基づく確率的定義(**ベイズ主義**)を前提とした手法が用いられるようになりました.





## ベイズの定理

まずは,ベイズ統計学の中核となる**ベイズ確率(逆確率)**,**ベイズの定理**などの基礎概念の概要を把握しましょう.

::: warn

ここでは,最低限の記法の意味などについて概要を解説します.
これ以前の基本的な確率計算や定義に関しては｢統計学入門｣, ｢データ活用の統計学｣などを,
ベイズやアルゴリズムの詳細に関しては｢データサイエンス実践｣｢データ活用の統計学実践｣などの講義を受講して下さい.

:::

ベイズ確率やベイズの定理は,1740年代に数学好きの牧師であったトーマス･ベイズによってまとめられました. ベイズは,神学への興味から,｢世界が原初神によって作られたこと｣を｢現在の事象｣によって証明できるか,という問題に関心を寄せていました. ベイズはこのような問題を解くために, 仮の確率を今現在の情報によって更新し,過去の出来事を推測するというアイデア(逆確率)をまとめました.

しかし,ベイズ自身はこれを発表せず, 1763年にリチャード・プライスによってベイズの遺稿が発表されたことで再注目されました(このことによって近年では,ベイズの定理が**ベイズ・プライスの定理**と呼ばれることもあります.)

古典的確率の定立に貢献したラプラスも同様の観点に注目した時期があり,ベイズの定理から確率的な推論を実施する方法などがまとめられましたが,当時の計算・データ環境などからそれ以上深められることはなく,古典的確率に則った頻度主義や伝統的統計学が発展していきます.

(cf. シャロン・バーチュ マグレイン (著), 異端の統計学 ベイズ, 草思社, 2013)

それでは,逆確率やベイズの定理がどのようなものかを見ていきましょう.

### 条件付き確率

事象Aの下での事象Bの条件付き確率

$$P(B|A) = \frac{P(B \cap A)}{P(A)}$$

 を変形した

 $$P(B \cap A) = P(A) P(B | A) $$

を乗法定理と呼びます.

このとき AとBは対称なので,

 $$P(B \cap A) = P(A \cap B) = P(B) P(A | B)  $$

も成り立ちます.

### ベイズの定理

$A$ を得られた結果, $H_1,H_2,...,H_k$ を原因としたとき,事象Aの下での事象$H_i$の条件付き確率は,

$$ P(H_i | A) = \frac{P(H_i \cap A)}{P(A)}$$

となります.

ただし, ここで $H_i$ は互いに排反で, $$ \bigcup_{i=1} H_i = \Omega $$ かつ $$ \sum_{i=1} P(H_i) =1 $$

このとき,乗法定理から

$$ P(H_i \cap A) = P(H_i)P(A | H_i)$$

が求まります. これを代入して,

$$ P(H_i | A) = \frac{P(H_i)P(A | H_i)}{P(A)} $$

となり,これをベイズの定理といいます.

また,

$$ P(A) = \sum_{i=1}^{k} P(A \cap H_i) = \sum_{i=1}^{k} P(H_i)P(A|H_i) $$

であるから,

$$ P(H_i |A) = \frac{P(H_i)P(A|H_i)}{\sum_{i=1}^{k} P(H_i)P(A|H_i) }$$

と表す場合もあります.

このとき, $P(H_i)$を(Aが起こる)**事前確率**,$P(H_i|A)$を(Aが起こる)**事後確率**といいます. ベイズ統計学ではしばしば事前確率に**主観確率**が用いられ,これを基礎とする統計的方法を**ベイズ統計学**といいます.

::: note

- 客観確率

頻度説では、事象$A$の起こる確率$P(A)$を生起回数の相対頻度で求めています.これは誰が計算しても同一の客観的な値といえます.

- 主観確率

研究者が主観的にある確率を与えて分析を行います. この場合確率は,研究者の経験,情報,知識によって異なる値が用いられます.
当然,主観確率によって結果は異なります. ただし,後に見るように多量のデータによって主観性を減らせる.


- 事前確率と事後確率の意味

**事前確率$P(H_i)$**は,データ$A$が観測される**前**の,仮説$H_i$に対する(主観的な)確信度を表します. つまり,データを観測する前に,どの仮説が真である可能性が高いかを表す確率です.

**事後確率$P(H_i|A)$**は,データ$A$が観測された**後**の,仮説$H_i$に対する確信度を表します. つまり,データ$A$が得られたという情報を踏まえた上で,どの仮説が真である可能性が高いかを表す確率です.

:::

ベイズの定理は,事前確率とデータから事後確率を計算する方法を提供します. この過程では,データが得られることで,仮説に対する確信度が更新されます. 例えば,事前確率が低かった仮説でも,データがその仮説を支持するものであれば,事後確率は高くなります. 逆に,事前確率が高かった仮説でも,データがその仮説と矛盾するものであれば,事後確率は低くなります.

条件付き確率の範囲では, ｢原因から結果の確率を計算｣しますが,ベイズの定理では結果から原因を考えています.


### 条件付き確率

事象Aが起こったと分かっている場合に事象Bの起こる確率

$$ P(B|A) = \frac{P(A \cap B)}{P(A)}$$

例:選ばれた壺から出るたまの確率を計算

壺に白,赤それぞれ3つの玉が入っている.白玉には1,1,2と数字,赤玉には1,2,2と数字が書かれている.
次に出る玉が白であることがわかっている場合に1の玉がでる確率は?

![](/images/slds/ch12/conditional_probability.png)

$$
P(1 | 白) = \frac{白 \cap 1}{P(白)} = \frac{2 / 6}{ 1/ 2} = \frac{2}{3}
$$


𝑃(玉の色|選んだ壺)であり, 𝑃(結果|原因)の計算

### ベイズ確率

事象Bが起こったと分かっている場合に,事象Aが起きている確率

$$ P(H_i | A) = \frac{P(H_i)P(A | H_i)}{P(A)} $$

例. 出た玉から壺が選ばれている確率を計算

2つの壺があり,

- 第1の壺には白玉が3個,黒玉が1個

- 第2の壺には白玉が1個,黒玉が２個

- $𝐻_1$:第1の壺から取り出す

- $𝐻_2$:第2の壺から取り出す

- $A$:白玉が出たという事象

とすると,いずれかの壺から玉を1個取り出したところ白玉であった,どちらの壺から取り出した確率が高いか.

![](/images/slds/ch12/beys_example.png)

まず,どちらの壺から取り出すかは**五分五分**であると仮定する. ここでこの仮定が完全に分析者の主観に基づくのであれば**主観確率**であり,何らかの実験等によって確率0.5であると確かめられている場合には**客観確率**とみなされる.

$$P(H_1) = P(H_2) = \frac{1}{2}$$

$$P(A|H_1) = \frac{3}{4}, \quad P(A|H_2) = \frac{1}{3}$$

であるから,

$$P(H_1|A) = \frac{\frac{1}{2} \cdot \frac{3}{4}}{\frac{1}{2} \cdot \frac{3}{4} + \frac{1}{2} \cdot \frac{1}{3}} = \frac{9}{13}$$

$$P(H_2|A) = \frac{\frac{1}{2} \cdot \frac{1}{3}}{\frac{1}{2} \cdot \frac{3}{4} + \frac{1}{2} \cdot \frac{1}{3}} = \frac{4}{13}$$

この｢$H_1$の壺が選ばれている｣という結果は,壺が選ばれる確率が等しいという主観確率が正しければ正しいと言えます.

この事例で計算されているのは 𝑃(選んだ壺|玉の色) であり, 𝑃(原因|結果)という計算をしていることになります.


このように事例を見てみると, 主観確率を利用した計算は,主観確率の正しさに依存しているためあまり実用性があるようには思えません.
そこで重要になってくるのが,**ベイズ更新**という概念です.

## ベイズ更新

### 独立性

事象$A$の起こる確率が他の事象$B$に影響されない場合,事象$A$と事象$B$は**独立である**という.

このとき

$$P(A) = P(A|B)$$

が成り立ちます. 乗法定理 $P(A \cap B) = P(B)P(A|B)$ より,

$$P(A \cap B) = P(A)P(B)$$

が成り立つ.

**例:** サイコロを2回投げて連続で1の目が出る確率を考える.

- 事象$A$: 1回目1が出る
- 事象$B$: 2回目1が出る

$$P(A \cap B) = \frac{1}{36}, \quad P(A) \cdot P(B) = \frac{1}{6} \cdot \frac{1}{6} = \frac{1}{36}$$

なので,事象$A$と$B$は独立といえる.


ベイズの目的は,複数のデータを利用して事後確率の推定を更新していくことにあります.

### 複数の事象からなる条件付き確率

複数の事象$A, B, C$がある場合の条件付き確率は以下のように表されます.

$$P(B \cap C | A) = \frac{P(A \cap B \cap C)}{P(A)}$$

この式は,乗法定理(積の法則)により以下のように書き換えられます.

$$\Leftrightarrow P(A \cap B \cap C) = P(B \cap C | A)P(A)$$

同様に,$A$が$B \cap C$の条件下で起こる確率は以下の通りです.

$$P(A | B \cap C) = \frac{P(A \cap B \cap C)}{P(B \cap C)}$$

これも積の法則として以下のように書き換えられます.

$$\Leftrightarrow P(A \cap B \cap C) = P(A | B \cap C)P(B \cap C)$$

これらの式を代入して整理すると,以下の関係が得られます.

$$P(A | B \cap C) = \frac{P(B \cap C | A)P(A)}{P(B \cap C)}$$

### ベイズ更新の適用

原因$H$と,現在の状況$B, C$があるとき,事後確率$P(H | B \cap C)$はベイズの定理により以下のように計算されます.

$$P(H | B \cap C) = \frac{P(B \cap C | H)P(H)}{P(B \cap C)}$$

もし事象$B$と$C$が独立であれば,条件付き確率$P(B \cap C | H)$は$P(B | H)P(C | H)$となり,分母の$P(B \cap C)$は$P(B)P(C)$となります. さらに,$P(H | C) = \frac{P(C | H)P(H)}{P(C)}$の関係を利用すると,上記の式は以下のように変形できます.

$$P(H | B \cap C) = \frac{P(B | H)P(C | H)P(H)}{P(B)P(C)} = \frac{P(B | H)P(H | C)}{P(B)}$$

ここで,情報$C$によって既に求められた事後確率$P(H | C)$を新しい事前確率$P(H)^*$とすると,ベイズ更新の式はより簡潔に表現できます.

$$P(H | B \cap C) = \frac{P(B | H)P(H)^*}{P(B)}$$

この方法により,情報が与えられるたびに事後確率を計算し,それを次のデータに対する事前分布として利用することで,分布の推定を逐次的に更新していくことができます.

### ベイズ統計学の性質

事前確率に関する情報がなく,$P(H)$が完全に主観的に決められたとしても,データ ($A,B,C, \dots$)が大量にある場合は,

$$P(H|A \cap B \cap C \cap D \dots) = \frac{P(A \cap B \cap C \cap D \dots|H) P(H)}{P(A \cap B \cap C \cap D \dots)}$$

以下のように段階的に更新を実施することができます.

まず,データ$A$が得られたとき:

$$P(H|A) = \frac{P(A|H)P(H)}{P(A)}$$

次に,データ$B$が得られたとき,前の事後確率$P(H|A) = \frac{P(A|H)P(H)}{P(A)} = P(H)^*$ を新しい事前確率として利用:

$$P(H|A \cap B) = \frac{P(B|H)P(H|A)}{P(B)} = \frac{P(B|H)P(H)^*}{P(B)} $$

さらに,データ$C$が得られたとき,前の事後確率$P(H|A \cap B) = P(H)^{**}$を新しい事前確率として利用:

$$P(H|A \cap B \cap C) = \frac{P(C|H)P(H)^{**}}{P(C)} $$

このように,データ$D, E, \dots$が得られるたびに,前の事後確率を事前確率として利用して更新を続けていきます. データ( $A,B,C,D, \dots$ )を大量に集めれば,最初に設定した事前確率$P(H)$の影響が少なくなり,事後確率 $P(H|A \cap B \cap C \cap D \dots)$が安定することが知られています. 


::: note

この性質は,**ベイズ的一致性(Bayesian consistency)**と呼ばれます. 具体的には以下のような性質が成り立ちます:

- **一致性**: データが増えるにつれて,事後確率分布は真のパラメータ値に収束します. つまり,サンプルサイズが無限大に近づくと,事後確率は真の値に集中していきます.

- **事後確率の安定性**: 異なる事前分布から出発しても,データが十分に多ければ,最終的な事後分布はほぼ同じ結果になります. これは,データが増えるにつれて,尤度関数$P(A \cap B \cap C \cap D \dots|H)$の影響が事前確率$P(H)$の影響を上回るためです.

- **事前確率の影響の減少**: データが少ないときは事前確率$P(H)$の選択が結果に大きく影響しますが,データが増えるにつれて,その影響は相対的に小さくなります. 最終的には,データの情報が支配的になり,事前確率の選択が結果に与える影響は限定的になります.

:::

しかし,このような更新には大量のデータが必要であることに加えて,データごとに分布を推定し直すには膨大な計算が必要となるため, ラプラスらの時代には現実的ではありませんでした.

現代では, 情報通信技術の発展によって大量のデータと,大量の計算が可能になりました.また,計算のためのアルゴリズム(マルコフ連鎖モンテカルロ法など)が発明されたことで,ベイズ更新に基づく推定が現実的な選択肢となりベイズ統計学が利用されるようになっています.

## マルコフ連鎖モンテカルロ法

### 尤度(Likelihood)

尤度とは,モデルのデータへの当てはまりの良さを表す統計量です.

- $\theta$を母数とする確率分布から観測データ$y_i$が発生した場合,その確率は$P(y_i|\theta)$と表されます.
- 尤度$L(\theta|Y)$は,観測されたデータ$Y = \{y_1, y_2, \dots, y_n\}$が与えられたときの,特定のパラメータ$\theta$の「もっともらしさ」を示す関数で,以下のように定義されます.

$$L(\theta|Y) = \prod_{i} P(y_i|\theta)$$

尤度はそのままでは計算しにくい場合が多いため,対数化した対数尤度を用いることが一般的です.

$$\log L(\theta|Y) = \sum_{i} \log P(y_i|\theta)$$

前段で説明したベイズ更新と尤度には密接な関係があります.

ベイズの定理は以下のように表されました:

$$P(H|A) = \frac{P(A|H)P(H)}{P(A)}$$

この式において,$P(A|H)$は「仮説$H$が真であるときにデータ$A$が観測される確率」であり,これは**尤度関数**に対応します.

一般的な尤度の説明ではパラメータを$\theta$で表しましたが,ベイズ統計学では仮説$H$をパラメータとみなすことができます. 複数のデータ$Y = \{y_1, y_2, \dots, y_n\}$が得られた場合,ベイズの定理は以下のようになります:

$$P(H|Y) = \frac{P(Y|H)P(H)}{P(Y)} = \frac{L(H|Y)P(H)}{P(Y)}$$

ここで,$P(Y|H) = \prod_{i} P(y_i|H)$は尤度関数$L(H|Y) = \prod_{i} P(y_i|H)$と一致します. したがって,ベイズの定理は尤度関数を用いて以下のように表現できます:

$$P(H|Y) \propto L(H|Y)P(H)$$

つまり,事後確率は「尤度×事前確率」に比例します. この関係から以下のことがわかります:

- 尤度$L(H|Y)$が大きいほど,その仮説$H$の事後確率$P(H|Y)$も大きくなります.
- データが増えるにつれて,尤度関数の影響が事前確率の影響を上回り,事後確率が安定していきます.
- ベイズ更新では,新しいデータが得られるたびに尤度関数を計算し,それと事前確率を組み合わせて事後確率を更新していきます.

### 最尤推定 (Maximum Likelihood Estimation)

この対数尤度を最大にするようなパラメータの推定量$\hat{\theta}$を推定することを**最尤推定**といいます.

$\hat{\theta}$は数理的に求めることが可能な場合もありますが,モデルが複雑な場合は困難なので機械的に求めることが多く,その手法の代表的なものがマルコフ連鎖モンテカルロ法(MCMC)です.

### マルコフ連鎖モンテカルロ法 MCMC(Markov chain Monte Carlo Method)

前段で説明したベイズ統計学において,事後確率$P(H|Y) \propto L(H|Y)P(H)$を計算するには,分母の正規化定数$P(Y)$を求める必要があります. しかし,モデルが複雑な場合やパラメータが多変数の場合,この正規化定数の計算は解析的に困難です. また,最尤推定においても,解析的に最尤推定量$\hat{\theta}$が求められない(難しい)場合があります.

このような場合に用いられるのが,計算機による繰り返し計算で少しずつパラメータの値を変化させ,最適な値を探し出す方法である**マルコフ連鎖モンテカルロ法(MCMC)**です.

::: note

- MCMCの基本的な仕組み

MCMCは以下のような手順で動作します:

1. **初期値の設定**: 複数の初期値$\theta$を適当に決めます.

2. **ランダムな探索**: ランダムに$\theta$を少し増減させます.

3. **尤度の評価**: 新しい$\theta$の値での尤度を計算し,前の値と比較します.

4. **移動の決定**: 尤度が改善したら,$\theta$をその方向にして次のステップに進みます. ただし,**メトロポリス法**などの手法では,たまに尤度が悪くなっても一定の確率でそちらに進むことで,局所最適解に陥ることを防ぎます.

5. **繰り返し**: この過程を繰り返すことで,パラメータ空間を探索し,最尤推定量や事後分布のサンプルを生成します.

![](/images/slds/ch12/mcmc.png)

:::

MCMCにより,ベイズ統計学における複雑な事後分布の推定や,最尤推定における困難な最適化問題を,計算機上で効率的に解決できるようになりました.

# ベイズ統計学による統計モデリング実践

それでは,実際にベイズ統計学に基づいた統計モデリングを実施してみましょう.
前章で重回帰で実施したものと良く似た[こちらのデータ](https://github.com/yakagika/yakagika.github.io/blob/main/slds_data/ch12/hierarchical_regression.csv)を事例として利用します.

| GPA | Scholarship | Study_Hours | Sports_hours | Part_time_Work | StudentID |
|-----|-------------|-------------|--------------|----------------|-----------|
| 1.348928 | True | 10.348188 | 5.398119 | 14.944201 | 0 |
| 1.968662 | False | 8.803971 | 3.799566 | 15.340118 | 1 |
| 2.246881 | True | 10.367043 | 5.139604 | 19.937536 | 2 |
| 1.167275 | True | 2.049724 | 4.229373 | 21.009315 | 3 |
| 3.295929 | True | 9.121312 | 5.227035 | 14.271377 | 4 |
| ... | ... | ... | ... | ... | ... |
| 0.974230 | False | 4.256551 | 0.396158 | 13.299289 | 185 |
| 2.208293 | False | 14.652655 | 1.969618 | 10.523032 | 186 |
| 0.786660 | False | 10.040932 | 7.733749 | 13.232559 | 187 |
| 2.068987 | True | 6.073965 | 8.289935 | 13.540597 | 188 |
| 2.531604 | True | 11.848414 | 4.501928 | 11.335318 | 189 |

各自でダウンロードして利用して下さい.


## 重回帰での結果確認

まずは,データの読み込みを行います. 必要なライブラリは各自で `pip install`してください.

~~~ py
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error



df = pd.read_csv('hierarchical_regression.csv'
                ,dtype={'GPA': float
                       ,'Scholarship': bool
                       ,'Study_Hours': float
                       ,'Sports_hours': float
                       ,'Part_time_Work': float
                       ,'StudentID':int})

print(df)

"""
          GPA  Scholarship  Study_Hours  Sports_hours  Part_time_Work  StudentID
0    1.348928         True    10.348188      5.398119       14.944201          0
1    1.968662        False     8.803971      3.799566       15.340118          1
2    2.246881         True    10.367043      5.139604       19.937536          2
3    1.167275         True     2.049724      4.229373       21.009315          3
4    3.295929         True     9.121312      5.227035       14.271377          4
..        ...          ...          ...           ...             ...        ...
185  0.974230        False     4.256551      0.396158       13.299289        185
186  2.208293        False    14.652655      1.969618       10.523032        186
187  0.786660        False    10.040932      7.733749       13.232559        187
188  2.068987         True     6.073965      8.289935       13.540597        188
189  2.531604         True    11.848414      4.501928       11.335318        189
"""

~~~

まずはデータを可視化してみます.

~~~ py

# ペアプロット
sns.pairplot(df
            ,vars=["GPA", "Study_Hours", "Sports_hours", "Part_time_Work"]
            ,hue="Scholarship"
            ,diag_kind="hist")
plt.suptitle("Pairplot with Scholarship", y=1.02)
plt.savefig('PairplotwithScholarship.png')
plt.close()

#joinplotで男女別に密度プロットを表示
fig = sns.jointplot(df
               ,x ="Study_Hours"
               ,y ="GPA"
               ,hue='Scholarship'
               ,joint_kws = dict(alpha=0.5))
plt.savefig('kde.png')
plt.close()
~~~


![](/images/slds/ch12/PairplotwithScholarship.png)

以前のデータと概ね似た傾向(奨学金ありが少し高い,勉強時間とGPAに相関,勉強時間とバイト時間に負の相関など,)が確認できます.
ただし,前回のデータと比べるとデータ全体のばらつきが大きいことが分かります.

![](/images/slds/ch12/kde-compare.png)

前回と同様の手法で,線形重回帰の実施と結果の確認を行います.

~~~ py

# 数量化
df = pd.get_dummies(df, columns=['Scholarship'], dtype='int')

#標準化
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df[['Scholarship_True'
   ,'Study_Hours'
   ,'Part_time_Work'
   ,'Sports_hours']] = scaler.fit_transform(df[['Scholarship_True'
                                               ,'Study_Hours'
                                               ,'Part_time_Work'
                                               ,'Sports_hours']])

#線形回帰
# 説明変数(X)と目的変数(y)に分割
X = df[['Scholarship_True', 'Study_Hours']]
y = df['GPA']


# 切片(定数項)を追加
X = sm.add_constant(X)
lm = sm.OLS(y, X).fit()
print("\n[通常の線形回帰の結果]\n")
print(lm.summary())
lm_preds = lm.predict(X)

plt.figure(figsize=(8, 6))
plt.scatter(df['GPA'], lm_preds, alpha=0.7, edgecolors="k")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Actual vs. Predicted")
plt.plot([df['GPA'].min(), df['GPA'].max()], [df['GPA'].min(), df['GPA'].max()], color="red", linestyle="--")  # 完全一致のライン
plt.grid()
plt.savefig('lm.png')
plt.close()

plt.figure(figsize=(16,8))
sns.kdeplot(lm_preds, label = 'Predicted')
sns.kdeplot(df['GPA'], label = 'Actual')
plt.title('Actual/Predicted')
plt.xlabel('GPA')
plt.ylabel('Density')
plt.legend()
plt.savefig('lm_kde.png')
plt.close()

"""
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    GPA   R-squared:                       0.444
Model:                            OLS   Adj. R-squared:                  0.438
Method:                 Least Squares   F-statistic:                     74.76
Date:                Tue, 04 Nov 2025   Prob (F-statistic):           1.38e-24
Time:                        16:50:17   Log-Likelihood:                -187.55
No. Observations:                 190   AIC:                             381.1
Df Residuals:                     187   BIC:                             390.8
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
====================================================================================
                       coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------------
const                2.0000      0.047     42.122      0.000       1.906       2.094
Scholarship_True     0.1385      0.047      2.917      0.004       0.045       0.232
Study_Hours          0.5620      0.047     11.835      0.000       0.468       0.656
==============================================================================
Omnibus:                       11.718   Durbin-Watson:                   1.974
Prob(Omnibus):                  0.003   Jarque-Bera (JB):               14.133
Skew:                          -0.457   Prob(JB):                     0.000853
Kurtosis:                       3.975   Cond. No.                         1.01
==============================================================================
"""
~~~

全般的に有意ではあるものの,精度がそれほど高くありません.
![](/images/slds/ch12/lm.png)
![](/images/slds/ch12/lm_kde.png)

グラフを見てみると, 元のデータは予測値に対して分散が大きくデータの分散を予測モデルが説明しきれていないことが分かります.
R2を確認しても,データに含まれている変数では全体の変動のうち44%ほどしか説明できていません.


## 過分散と個別差

このように,観察データの分散が,モデルの予測から逸脱しており,モデルではデータの分散が説明できていない状態を**過分散**といいます.

モデルの説明力を上げるためには,このようなモデルによって説明できていないばらつきを説明する拡張が必要となります.

ここでは,｢データ(の観測対象)=学生｣なので,｢ばらつき=学生差｣と仮定してみます.
例えば,そもそも過去の学習経験,勉強環境などにより,ベースとなる学力が学生それぞれで異なるなど,学生差によるばらつきを表現するために線形モデルを拡張した**一般化線形モデル**を構築してみましょう.


## 一般化線形モデル(GLM)

**一般化線形モデル(Generalized Linear Model, GLM)**は,線形回帰分析を一般化した統計モデルです. 線形回帰分析では以下の式における

$$
Y_i = \beta_0 + \beta_1 X_i + \epsilon_i \quad (i=1,2,\dots,n)
$$

**誤差項** $\epsilon_i$ のみが**正規分布**に従うと仮定して分析を実施していました.

$$
\epsilon_i \sim N(0, \sigma^2)
$$

これに対し,一般化線形モデルは以下の3つの要素から構成されます:

1. **確率分布**: 目的変数$y_i$が従う確率分布(正規分布,ポアソン分布,二項分布など)
2. **線形予測子**: 説明変数の線形結合$\eta_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \cdots$
3. **リンク関数**: 目的変数の期待値$E[y_i]$と線形予測子$\eta_i$を結び付ける関数$g(E[y_i]) = \eta_i$

線形回帰は,一般化線形モデルの特殊ケース(正規分布 + 恒等リンク関数)として捉えることができます. 一般化線形モデルにより,正規分布以外の分布や,非線形な関係もモデル化できるようになります.

ベイズ統計学のモデルにおいて最尤推定する対象は, モデルの母数 $\theta$であり,
データがどのような分布であるかを観察し,それを再現するモデルを構築します.

そこで,今回の目的変数であるGPAの分布を確認してみましょう.

~~~ py
plt.figure(figsize=(8, 5))
sns.kdeplot(df["GPA"], fill=True, bw_adjust=0.5)
plt.title("Kernel Density Estimate of GPA")
plt.xlabel("GPA")
plt.ylabel("Density")
plt.grid(True)
plt.savefig('kde-gpa.png')
plt.close()
~~~

![](/images/slds/ch12/gpa-kde.png)

カーネル密度プロットの結果から,今回のデータは正規分布していると仮定して問題なさそうです.

$$ y_i \sim N(\mu_i, \sigma^2) $$

ここで,今回は正規分布の母数である平均 $\mu$ を推定する目的としてみます.

::: warn 

モデルの設計では分散 $\sigma$ を推定の目的とすることも可能ですが,単純化のために固定とします.
今回は説明用の単純なモデルですが,必要に応じてより複雑なモデルを資料に追加していきます.

:::

このとき,説明変数としてgpaに影響するもの配下のように仮定します.

- $S_t$ (Study Hours): 勉強時間
- $S_s$ (Scholarship): 奨学金
- $\alpha_i$: 学生個別のもともとの学力（ランダム切片）

これらの変数を用いて, $\mu$ を表す式を以下のように立てます.

$$\mu_i = \alpha_i + \beta_{st} \cdot S_t + \beta_{ss} \cdot S_s$$

このような式を,**線形予測子(linear predictor)**といいます.

::: note

線形予測子は,説明変数とパラメータの線形結合で構成される式です. 

一般化線形モデル(GLM)では,線形予測子$\eta_i$と目的変数の期待値$E[y_i]$をリンク関数$g(\cdot)$で結び付けます:

$$g(E[y_i]) = \eta_i = \alpha_i + \beta_{st} \cdot S_t + \beta_{ss} \cdot S_s$$

今回は正規分布を仮定しているため,恒等リンク関数(identity link function) $g(x) = x$ を使用します. 恒等リンク関数では,

$$g(E[y_i]) = E[y_i] = \mu_i = \eta_i$$

となり,$\mu_i = E[y_i] = \eta_i$という関係が成り立ちます. これにより,線形回帰と同じ形式になります.

他の分布では,例えば:

- ポアソン分布: 対数リンク関数 $g(E[y_i]) = \log(E[y_i]) = \eta_i$
- 二項分布: ロジットリンク関数 $g(E[y_i]) = \log\left(\frac{E[y_i]}{1-E[y_i]}\right) = \eta_i$

などが用いられます.

今回は線形モデルとの接続のために,正規分布を仮定していますが,そもそもデータが正規分布では説明できないことが明らかな場合には,適した分布を選択することでモデルの精度が格段に上がります.

:::

ここで,解くべき問題は,

$$E[y_i] = \mu_i = \alpha_i + \beta_{st} \cdot S_t + \beta_{ss} \cdot S_s$$

となるような$\alpha_i, \beta_{st}, \beta_{ss}$を推定することです.

## 個体差のモデリング

恒等リンク関数を用いたモデリングでは,線形回帰と同じ形式の式となりますが,
一般化線形モデルでは全体の分布を仮定しているため個体差をモデルに取り組むことが可能となります.



### 線形回帰での問題

個体差をモデルに取り込もうとする場合,線形回帰では以下のような問題が発生します:

- **ダミー変数の導入**: 各学生の個別の学力を推定するために,学生ごとにダミー変数を導入する方法が考えられます.

- **データ数が少ない場合の問題**: 各学生毎にデータ数が少ない場合(今回は1人1データ),各ダミー変数は誤差と等しくなってしまいます.

- **過学習の問題**: 結果として,データ = 予測値 ($\hat{y}_i = y_i$) としているのと変わらなくなります. これは推定の意味がなく,**過学習**を起こしている状態です.

### ベイズ推論による解決

ベイズ統計学では,この問題を以下のように解決します:

- **階層構造の導入**: 各学生の学力$\alpha_i$に対して,事前分布として正規分布$\alpha_i \sim N(\mu_{\alpha}, \sigma_{\alpha}^2)$を設定します. これにより,**階層ベイズモデル(hierarchical Bayesian model)**または**ランダム効果モデル(random effects model)**を構築します.

- **分布の母数を推定**: 推定するのは個別の学力$\alpha_i$ではなく,その分布の母数$(\mu_{\alpha}, \sigma_{\alpha})$です. これにより,データ数が少なくても,全体の分布から情報を借用(**borrowing strength**, 情報の共有)して推定を行うことができます. 各学生のデータが少なくても,他の学生のデータと組み合わせることで,より安定した推定が可能になります.

- **新しいデータへの対応**: 分布の母数$(\mu_{\alpha}, \sigma_{\alpha})$が推定されているため,新しい学生のデータが得られた場合でも,推定された分布$N(\mu_{\alpha}, \sigma_{\alpha}^2)$に基づいて学力を推定することが可能になります. これにより,汎化性能の高いモデルを構築できます.


![](/images/slds/ch12/random_image.png)


それでは実際に,モデルを構築してみましょう.

### モデルの仮定

階層ベイズモデルでは,仮説に従って以下のように分布を設定します.

- **仮説: 基礎学力は学生によって異なる**
  - 個別に異なる$\alpha_i$

- **仮定: 基礎学力は正規分布に従う**
  - $\alpha_i \sim N(\mu_{\alpha}, \sigma_{\alpha}^2)$
  - これを**事前分布(prior distribution)**といいます.

- **更にそれぞれの母数の分布を仮定する**
  - $\mu_{\alpha} \sim N(0, 1)$
  - $\sigma_{\alpha} \sim HN(1)$
  - ここで,$HN$は**半正規分布(Half-Normal distribution)**を表します.

![](/images/slds/ch12/dist_setting.png)

このように,パラメータの分布のパラメータ(超パラメータ)についても分布を仮定することで,階層的な構造を持つベイズモデルを構築します. これは**階層事前分布(hierarchical prior)**と呼ばれます.

### ランダム傾きとランダム切片

これまで,学生の基礎学力の違い(ランダム切片$\alpha_i$)について考えてきましたが,他にも個体差として考慮できる要素があります.

- **仮説: 勉強時間による効果は人によって違う**

ただし,学生個別の個体差$\alpha_i$(ランダム切片)のように,学生個別の勉強時間あたりのGPAの上昇率$\beta_{st,i} \cdot S_t$という推定は,今回のデータではモデル化**できません**.

このような個別の傾きを**ランダム傾き(random slope)**といいます.

#### なぜモデル化できないのか?

- **学生1人につき1つしかデータがない**: 今回のデータでは,各学生について1つの観測値しかありません.

- **切片はそれぞれの値から推定できる**: 切片$\alpha_i$は,以下のように各学生のデータから直接推定できます:
  $$\alpha_i = y_i - \beta_{st} \cdot S_t - \beta_{ss} \cdot S_s$$

- **傾きは複数の観測点が必要**: 傾きは「変化の傾向(勾配)」なので,推定には複数の観測点が必要です. 傾き$\beta_{st,i}$を推定するには,少なくとも2点以上のデータが必要で,以下のように計算されます:
  $$\beta_{st,i} = \frac{y_i - y_j}{S_{t,i} - S_{t,j}}$$

そのため,1人1データしかない今回のケースでは,学生ごとのランダム傾きを推定することはできません. ランダム傾きをモデル化するには,各学生について複数の時点でのデータ(縦断データ)が必要になります.

![](/images/slds/ch12/random_slope.png)

### ランダム傾きの分布推定

学生毎に学習効率が異なると仮定できますが,個別の学習効率は推定できません. つまり,$\beta_{st,i} = 0.2$のような個別の数値は出せません.

そこで,個別の学習効率の**分布**を推定するというアプローチを取ります.

- **ランダム傾きの分布を仮定**: $\beta_{st} \sim N(\mu_{st}, \sigma_{st}^2)$として,勉強時間の係数が正規分布に従うと仮定します.

- **超事前分布の設定**: さらに,この分布の母数に対して超事前分布を設定します.
  - $\mu_{st} \sim N(0, 1)$
  - $\sigma_{st} \sim HN(1)$

このモデリングでは個別の値は分かりませんが,このような分布であるという情報はモデルに盛り込むことができます.

- **予測への影響**: 実際の予測では,推定値として$\hat{y}_i = E[\mu_i]$を用いるので,予測精度には(あまり)差異は出ません.

- **区間推定への影響**: ただし,信頼区間や予測区間には影響があります. ランダム傾きの分布を考慮することで,個体差による不確実性を適切に反映した区間推定が可能になります.

### 奨学金の効果のモデル化

奨学金も同様にモデル化することができます:

- **学生によって奨学金の効果が異なる**: 勉強時間と同様に,奨学金の効果も学生によって異なると仮定できます.

- **ランダム傾きとしてモデル化**: $\beta_{ss} \sim N(\mu_{ss}, \sigma_{ss}^2)$として,奨学金の係数が正規分布に従うと仮定します.

- **超事前分布の設定**: この分布の母数に対して超事前分布を設定します:
  - $\mu_{ss} \sim N(0, 1)$
  - $\sigma_{ss} \sim HN(1)$

このように,勉強時間の効果と同様に,奨学金の効果についてもランダム傾きとしてモデル化することで,学生間の個体差を考慮した統計モデルを構築できます.

## モデル全体像

これまで説明してきた内容を整理すると,以下のような階層ベイズモデルになります:

### 推定する分布

$$y_i \sim N(\mu_i, \sigma^2)$$

ここで,$y_i$は学生$i$のGPAです.

### 線形予測子

$$\mu_i = \alpha_i + \beta_{st} \cdot S_t + \beta_{ss} \cdot S_s$$

### 尤度関数

$$p(y | \alpha, \beta_{st}, \beta_{ss}, \sigma) = \prod_{i=1}^{N} N(y_i | \mu_i, \sigma^2)$$

ここで,$\mu_i = \alpha_i + \beta_{st} \cdot S_t + \beta_{ss} \cdot S_s$です.

### 事前分布

- $\alpha_i \sim N(\mu_{\alpha}, \sigma_{\alpha}^2)$: 学生個別の基礎学力(ランダム切片)
- $\beta_{st} \sim N(\mu_{st}, \sigma_{st}^2)$: 勉強時間の効果(ランダム傾き)
- $\beta_{ss} \sim N(\mu_{ss}, \sigma_{ss}^2)$: 奨学金の効果(ランダム傾き)

### 超事前分布

- $\mu_{\alpha} \sim N(0, 1)$, $\sigma_{\alpha} \sim HN(1)$
- $\mu_{st} \sim N(0, 1)$, $\sigma_{st} \sim HN(1)$
- $\mu_{ss} \sim N(0, 1)$, $\sigma_{ss} \sim HN(1)$


![](/images/slds/ch12/model_overview.png)

このモデルにより,学生間の個体差を考慮しながら,勉強時間と奨学金がGPAに与える影響を推定することができます.

