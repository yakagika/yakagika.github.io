<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width">

        <title>yakagika - 特別講義DS Ch14 ニューラルネットワーク(画像認識)</title>

        <!-- Stylesheets. -->
        <link rel="stylesheet" type="text/css" href="../style.css?v=0">

        <!-- RSS. -->
        <link rel="alternate" type="application/rss+xml" title="yakagika" href="https://yakagika.github.io/rss.xml">

        <!-- Metadata. -->
        <meta name="keywords" content="yakagika Haskell ExchangeAlgebra">
        <meta name="description" content="Personal home page and blog of yakagika.">
        
        <!-- KaTeXのスタイルシートとJavaScriptのリンクを動的に挿入 -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" integrity="sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js" integrity="sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
        <style>
            .katex-display {
                display: block;
                margin: 1em 0;
                text-align: center;
            }

            .katex .frac {
                vertical-align: baseline;
                -webkit-vertical-align: baseline; /* Safari用のベンダープリフィックス */
            }

            .katex .sqrt {
                vertical-align: baseline;
                -webkit-vertical-align: baseline; /* Safari用のベンダープリフィックス */
            }

            .katex .strut {
                height: 1em;
                -webkit-height: 1em; /* Safari用のベンダープリフィックス */
            }

            .katex .base {
                font-family: 'KaTeX_Main', 'Arial', sans-serif;
            }

            /* Safari専用のスタイルを追加 */
                @media screen and (-webkit-min-device-pixel-ratio:0) {
                    .katex {
                        line-height: normal !important;
                    }
                }
            @media not all and (min-resolution: .001dpcm) {
                @supports (-webkit-appearance:none) {
                    .katex {
                        line-height: normal !important;
                    }
                }
            }
        </style>
        
        <meta property="og:description" content="資料" />
    </head>
    <body>
        <div id="navigation">
            <h1>Contents</h1>
            <a href="../">Home</a>
            <a href="../posts.html">Blog</a>
            <a href="../lectures.html">Lecture</a>
            <a href="../research.html">Research</a>
            <a href="../contact.html">Contact</a>
            <!-- <a href="/cv.html">CV</a> -->
            <h1>Links</h1>
            <a href="http://github.com/yakagika">GitHub</a>
            <a href="https://researchmap.jp/k-akagi">researchmap</a>

        </div>

        <div id="content">
    <h1>特別講義DS Ch14 ニューラルネットワーク(画像認識)</h1>
<div class="soft">
    資料<br />
    Published on 2024-09-28 under the tag <a title="All pages tagged 'datascience'." href="../tags/datascience.html">datascience</a>, <a title="All pages tagged 'statistics'." href="../tags/statistics.html">statistics</a>, <a title="All pages tagged 'python'." href="../tags/python.html">python</a>
</div>

<!-- 前後の章へのナビゲーション -->
<div class="chapter-navigation">
    <nav>
        
            <a class="nav-link prev" href="slds13.html">← Previous Chapter</a>
        
        
            <a class="nav-link next" href="slds15.html">Next Chapter →</a>
        
    </nav>
</div>

<br>

<div class="toc"><div class="header">Table of Contents</div>
<ul>
<li><a href="#ニューラルネットワーク概要執筆中" id="toc-ニューラルネットワーク概要執筆中"><span class="toc-section-number">1</span> ニューラルネットワーク概要(執筆中)</a>
<ul>
<li><a href="#パーセプトロン" id="toc-パーセプトロン"><span class="toc-section-number">1.1</span> パーセプトロン</a></li>
<li><a href="#ニューラルネットワークの構成" id="toc-ニューラルネットワークの構成"><span class="toc-section-number">1.2</span> ニューラルネットワークの構成</a></li>
<li><a href="#ニューラルネットワークの学習" id="toc-ニューラルネットワークの学習"><span class="toc-section-number">1.3</span> ニューラルネットワークの学習</a></li>
</ul></li>
<li><a href="#画像認識" id="toc-画像認識"><span class="toc-section-number">2</span> 画像認識</a>
<ul>
<li><a href="#代表的なcnnモデル" id="toc-代表的なcnnモデル"><span class="toc-section-number">2.5</span> 代表的なCNNモデル</a></li>
<li><a href="#顔による年齢識別" id="toc-顔による年齢識別"><span class="toc-section-number">2.6</span> 顔による年齢識別</a>
<ul>
<li><a href="#画像ファイルの形式" id="toc-画像ファイルの形式"><span class="toc-section-number">2.6.1</span> 画像ファイルの形式</a></li>
<li><a href="#画像認識の実施" id="toc-画像認識の実施"><span class="toc-section-number">2.6.2</span> 画像認識の実施</a></li>
</ul></li>
</ul></li>
</ul>
</div>
<h2 data-number="1" id="ニューラルネットワーク概要執筆中"><span class="header-section-number">1</span> ニューラルネットワーク概要(執筆中)</h2>
<p>この章と次の章ではニューラルネットワークの概要を学び,画像や文章などの非構造化データを利用した学習を扱います.
本講義はニューラルネットワークモデル等を直接開発,学習することは行わないため詳細については扱いません.そのため,この節では何を行っているのかの概要を掴むための基礎知識を学習します.</p>
<h3 data-number="1.1" id="パーセプトロン"><span class="header-section-number">1.1</span> パーセプトロン</h3>
<p><strong>ニューラルネットワーク（Neural Network）</strong>は, 人間の脳の神経回路を模倣した数学モデルです. 脳は1000億個のニューロン(神経細胞)が軸索を通じて結合したネットワークであり,特定のニューロンが発した電気信号が一定の閾値を超えるとつながっているニューロンも電気信号を発します. このような仕組みを数学的に模倣したものに<strong>パーセプトロン</strong>があります.</p>
<p><img src="../images/ch14-NN.png" /></p>
<p>上図のパーセプトロンでは,2つのニューロンから発せられた信号(<span class="math inline">\(x_1,x_2 = 0,1\)</span>)がそれぞれ特定の重み付け(<span class="math inline">\(w_1,w_2\)</span>)をされて,yに伝達されている様子が示されています. ここで重みは,それぞれのニューロンからの信号の重要性を表していると考えましょう. 例えば,<span class="math inline">\(y\)</span>を以下のように定めると,<span class="math inline">\(y\)</span>は重み付けされた<span class="math inline">\(x_1,x_2\)</span>が特定の閾値<span class="math inline">\(\theta\)</span>を超えると<span class="math inline">\(1\)</span>,超えなかった場合は<span class="math inline">\(0\)</span>を発するという意味になります.</p>
<p><span class="math display">\[
y = \begin{cases}
1 &amp; (w_1x_1 + w_2x_2 &gt; \theta) \\
0 &amp; (w_1x_1 + w_2x_2 \leq \theta)
\end{cases}
\]</span></p>
<p>パーセプトロンはコンピュータの計算における論理演算との関連が深く,論理演算を実装することができます.
例えば,<code>AND演算</code>と<code>OR演算</code>を考えてみましょう. <code>TRUE</code>を<code>1</code>,<code>FALSE</code>を<code>2</code>とした場合のそれぞれの真偽値表は,以下のようになります.</p>
<ul>
<li>AND</li>
</ul>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(x_1\)</span></th>
<th style="text-align: center;"><span class="math inline">\(x_2\)</span></th>
<th style="text-align: center;"><span class="math inline">\(~y~\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<ul>
<li>OR</li>
</ul>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(x_1\)</span></th>
<th style="text-align: center;"><span class="math inline">\(x_2\)</span></th>
<th style="text-align: center;"><span class="math inline">\(~y~\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>このような演算は例えば以下のように<span class="math inline">\(w_1,w_2,\theta\)</span>を定めると実現できます.</p>
<ul>
<li><code>AND</code></li>
</ul>
<p><span class="math display">\[
y = \begin{cases}
1 &amp; (x_1 + x_2 &gt; 1) \\
0 &amp; (x_1 + x_2 \leq 1)
\end{cases}
\]</span></p>
<ul>
<li><code>OR</code></li>
</ul>
<p><span class="math display">\[
y = \begin{cases}
1 &amp; (0.5x_1 + 0.5x_2 &gt; 0.2) \\
0 &amp; (0.5x_1 + 0.5x_2 \leq 0.2)
\end{cases}
\]</span></p>
<p>このとき,例えばOR演算を実装する<span class="math inline">\(y\)</span>を,<span class="math inline">\(y = f(w_1x_1+w_2x_2)\)</span> として,</p>
<p><span class="math display">\[
f(x) = \begin{cases}
1 &amp; (x &gt; 0.2) \\
0 &amp; (x \leq 0.2)
\end{cases}
\]</span></p>
<p>のように表すことができます. このような特定のニューロンの発火の有無を決める関数を<strong>活性化関数(activation function)</strong>と呼びます.</p>
<p>パーセプトロンでは,活性化関数として,特定の閾値に重み付け入力合計値が達するか否かによって出力が0か1のいずれかになります.このような,0/1が特定の閾値で極端に切り替わる関数を<strong>ステップ関数</strong>,<strong>階段関数</strong>などと呼びます.</p>
<h3 data-number="1.2" id="ニューラルネットワークの構成"><span class="header-section-number">1.2</span> ニューラルネットワークの構成</h3>
<p>これまでに説明してきたのパーセプトロンは最初の<span class="math inline">\(x_1,x_2\)</span>からなる0層と入力を受け取る<span class="math inline">\(y\)</span>の2層から構成されていますが,ニューロンの数や,層の数を増やして様々な複雑な条件を表現することが可能になります.</p>
<p>基本的なニューラルネットワークではネットワークを入力層,隠れ層,出力層の3層に分類します.</p>
<p><img src="../images/ch14-NN1.png" /></p>
<p>ここで中間層においてn個の入力ニューロン<span class="math inline">\((x_1,x_2,...,x_n)\)</span>からy個の出力ニューロン<span class="math inline">\((y_1,y_2,...,y_m)\)</span>に入力がある場合,各出力ニューロンの発火条件は以下のように行列形式で表現されます.</p>
<p><span class="math display">\[
\begin{align*}
&amp;Y = f(WX + B) \\
&amp;W: 重み行列 ; (m \times n) \\
&amp;X: 入力ベクトル ; (n \times 1) \\
&amp;B: バイアスベクトル ; (m \times 1) \\
&amp;f: 活性化関数（要素ごとに適用される非線形関数） \\
&amp;Y: 出力ベクトル ; (m \times 1) \\
\end{align*}
\]</span></p>
<p>具体的には, 重み行列 <span class="math inline">\(W\)</span>, 入力ベクトル <span class="math inline">\(X\)</span>, バイアスベクトル <span class="math inline">\(B\)</span> を以下のように定義します.</p>
<p>各入力ニューロン <span class="math inline">\(x_i\)</span> から出力ニューロン <span class="math inline">\(y_j\)</span> への接続には重みが存在し, それを <span class="math inline">\(w_{ij}\)</span> とします. このとき, 重み行列 <span class="math inline">\(W\)</span> は次のように表されます:</p>
<p><span class="math display">\[
W =
\begin{bmatrix}
w_{11} &amp; w_{12} &amp; \cdots &amp; w_{1n} \\
w_{21} &amp; w_{22} &amp; \cdots &amp; w_{2n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
w_{m1} &amp; w_{m2} &amp; \cdots &amp; w_{mn}
\end{bmatrix}
\]</span></p>
<p>入力ベクトル X :
<span class="math display">\[
X =
\begin{bmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{bmatrix}
\]</span></p>
<p>バイアスベクトル B :
<span class="math display">\[
B =
\begin{bmatrix}
b_1 \\
b_2 \\
\vdots \\
b_m
\end{bmatrix}
\]</span></p>
<p>出力ベクトル Y :
<span class="math display">\[
Y =
\begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_m
\end{bmatrix}
\]</span></p>
<p>このとき, 発火条件は活性化関数を利用して以下のように計算されます.</p>
<p><span class="math display">\[
Y = f(WX + B)
\]</span></p>
<p>単純なニューラルネットワークでは, 隠れ層において, 全てのニューロンが結合している<strong>全結合層（Affine Layer）</strong>が使用されています. 全結合層は, 行列演算を用いて入力データを重み付けし, バイアスを加算する操作を行います. これにより, ネットワークが入力データの全体的な特徴を学習することが可能になります.</p>
<p>パーセプトロンでは,活性化関数としてステップ関数が利用されており,その出力は必ず0か1でした.</p>
<p>ニューラルネットワークでは,通常, 非線形の<strong>シグモイド関数</strong>や<strong>ReLU関数(Rectified Linear Unit function)</strong>
などが利用され出力が0,1以外の値を取ります.</p>
<ul>
<li><code>シグモイド関数</code></li>
</ul>
<p><span class="math display">\[
f(x) = \frac{1}{1+exp(-x)}
\]</span></p>
<p>出力を0～1の範囲にマッピングするため, 確率を表現する場面で使われることがあります.</p>
<ul>
<li><code>ReLu</code></li>
</ul>
<p><span class="math display">\[
f(x) = \begin{cases}
x &amp; (x &gt; 0) \\
0 &amp; (x \leq 0)
\end{cases}
\]</span></p>
<p>ReLUは計算が効率的で, 学習を早める効果があるため, 現在最も広く利用されている活性化関数です.</p>
<p><img src="../images/ch14-NN2.png" /></p>
<p>出力層では, 解きたい問題の性質に応じて適切な活性化関数が選択されます.</p>
<div class="note">
<pre><code>1.  回帰問題（数値を予測する場合）:</code></pre>
<p>出力層には<strong>恒等関数（Identity Function）</strong>が使用されます. この場合, 出力はそのまま数値として扱われます.</p>
<p><span class="math display">\[
f(x) = x
\]</span></p>
<pre><code>2.  分類問題（カテゴリを予測する場合）:</code></pre>
<p>出力層にはSoftmax関数が使用されることが一般的です. Softmax関数は, 出力を確率分布に変換します.</p>
<p><span class="math display">\[
f(x_i) = \frac{e^{x_i}}{\sum_{j} e^{x_j}} \\
\]</span></p>
<p><span class="math inline">\(x_i\)</span> : i番目の出力ニューロンの値,<span class="math inline">\(f(x_i)\)</span> : i 番目のカテゴリの確率,<span class="math inline">\(\sum_j f(x_j)\)</span> = 1 : 全てのカテゴリの確率の総和が1になる.</p>
<p>Softmax関数は, 手書き文字認識や画像分類タスクのように, 複数のクラスを予測する場面で広く使われています.</p>
</div>
<p>これらのレイヤによって一般的なニューラルネットワークは以下のようなレイヤとして表せます.</p>
<p><img src="../images/ch14-NN-normal.png" /></p>
<h3 data-number="1.3" id="ニューラルネットワークの学習"><span class="header-section-number">1.3</span> ニューラルネットワークの学習</h3>
<p>パーセプトロンはそれぞれの重みを人間が設定する必要がありました.しかし,複雑な条件を満たすネットワークの重みを人間が設定するのは現実的ではありません.そこで,<strong>それぞれの重みを機械学習によってデータから自動で学ぶようにしたものがニューラルネットワークです</strong>.</p>
<p>ニューラルネットワークの学習では,ネットワーク内の重み <span class="math inline">\((w_1, w_2, \dots, w_n)\)</span> とバイアス (<span class="math inline">\(b\)</span>) の値を適切に調整することで,モデルが入力データから期待される出力を生成できるようにします.このプロセスは次の手順で進行します.</p>
<div class="note">
<ul>
<li><h3 id="順伝播と損失関数の計算">順伝播と損失関数の計算</h3></li>
</ul>
<p>入力データをネットワークに通し,各層のニューロンで計算が行われ,最終的な出力が生成されます. この出力は予測値として解釈されます. このようなデータにに基づく計算の過程を<strong>順伝播（Forward Propagation）</strong>といいます.</p>
<p>例えば,手書きの<code>0~9</code>の数字を認識するタスクでは <span class="math inline">\(m \times n\)</span> ピクセルの画像データが入力され、最終出力層で<code>0~9</code>のいずれかを予測します.</p>
<p>学習のためにはネットワークの予測値と実際の正解データとの差を数値化して,より良い重みを発見する必要があります.その際の予測値と正解データとの差を数値化するための関数を損失関数と呼びます.この損失関数は、ネットワークがどれだけ誤った予測をしているかを示す指標となります。</p>
<pre><code>一般的な損失関数の例:
•   平均二乗誤差 (Mean Squared Error, MSE): 回帰タスクで使用</code></pre>
<p><span class="math display">\[
L = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2
\]</span></p>
<pre><code>交差エントロピー損失 (Cross-Entropy Loss): 分類タスクで使用</code></pre>
<p><span class="math display">\[
L = -\sum_{i=1}^{N} y_i \log(\hat{y}_i)
\]</span></p>
<p>ここで,<span class="math inline">\(y_i\)</span>は正解ラベル, <span class="math inline">\(\hat{y}_i\)</span> は予測値を示します.</p>
</div>
<div class="note">
<ul>
<li><h3 id="逆伝播と重みの修正">逆伝播と重みの修正</h3></li>
</ul>
<p>ニューラルネットワークはでは損失関数を基に, 誤差をネットワーク内で逆方向に伝播させ, 各ニューロンの重みとバイアスを更新する手法します. これを,<strong>誤差逆伝播法(Backpropagation)</strong>といいます.このとき, 微分を用いて重みやバイアスがどの程度影響を与えるかを計算します.</p>
<pre><code>- 勾配降下法（Gradient Descent）</code></pre>
<p>逆伝播によって得られた勾配を用いて, 重みとバイアスを更新する手法の最も基本的なものとして勾配降下法があります</p>
<p><span class="math display">\[
W_{new} = W_{old} - \eta \frac{\partial L}{\partial W}
\]</span></p>
<p>ここで,<span class="math inline">\(L\)</span> : 損失関数（誤差を表す関数）,<span class="math inline">\(y_i\)</span>:正解ラベル,<span class="math inline">\(\hat{y}_i\)</span> :予測値,<span class="math inline">\(\frac{\partial L}{\partial W}\)</span> : 重み <span class="math inline">\(W\)</span> に関する損失関数の勾配,<span class="math inline">\(\eta\)</span> : 学習率（Learning Rate） 重みの更新量を決定する定数です.</p>
<p>例として, シンプルな1次元関数の最小化を考えます.
<span class="math display">\[L(w) = (w - 2)^2\]</span>
ここで, 最小値は <span class="math inline">\(w = 2\)</span> です.</p>
<ol type="1">
<li>初期値を <span class="math inline">\(w = 0\)</span> , 学習率を <span class="math inline">\(\eta = 0.1\)</span> とします.</li>
<li>勾配を計算します:</li>
</ol>
<p><span class="math display">\[\frac{\partial L}{\partial w} = 2(w - 2)\]</span>
初期値 <span class="math inline">\(w = 0\)</span> のとき,
<span class="math display">\[\frac{\partial L}{\partial w} = -4 \]</span></p>
<ol start="3" type="1">
<li>重みを更新します:
<span class="math display">\[w_{new} = w_{old} - \eta \cdot \frac{\partial L}{\partial w} \]</span>
<span class="math display">\[w_{new} = 0 - 0.1 \cdot (-4) = 0.4 \]</span></li>
</ol>
<p>この処理を繰り返していくと重みは理論的な最小値の2に近づいていきます.</p>
<p><img src="../images/ch14-WeightUpdates.png" /></p>
</div>
<div class="note">
<ul>
<li><h3 id="繰り返し学習">繰り返し学習</h3></li>
</ul>
<p>順伝播, 損失計算, 逆伝播のプロセスを繰り返し, ネットワークが徐々にデータの特徴を学習します. この反復的なプロセスを<code>エポック（Epoch）</code>と呼びます. 十分なエポックを実行することで, モデルは訓練データに対して高い精度を達成することが期待されます.</p>
<p>学習では, 全てのデータを一度に処理するのではなく, <code>バッチ処理（Batch Processing）</code> と呼ばれる手法を使用するのが一般的です. データセットをいくつかの小さなグループ（バッチ）に分割し, 各バッチごとに順伝播と逆伝播を実行します.</p>
<p>データセットをいくつかの小さなバッチに分割して処理する手法を <code>ミニバッチ学習（Mini-Batch Learning）</code>といい,メモリの使用料を抑え,またGPUの並列処理能力を最大限に利用できるという実施上の利点と,ゼータ全体を満遍なく学習することで,勾配のばらつきが抑えられるという学習能力面の利点もあります.</p>
<p>例えば, データセットが10,000個のサンプルで構成されている場合, バッチサイズを100に設定すると, モデルは100個のデータを1つのバッチとして扱い, 全部で100のバッチを処理することになります. 1エポックでは100回の更新が行われ, これを複数回繰り返して学習が進行します.</p>
<p>ミニバッチ学習はモデルの効率的な学習とメモリ使用量のバランスを取るため, 実務で最も一般的に使われています. 例えば, バッチサイズを32や64に設定することが多いです.</p>
</div>
<h2 data-number="2" id="画像認識"><span class="header-section-number">2</span> 画像認識</h2>
<p>こちらの節では, ニューラルネットワークの一種である,畳み込みニューラルネットワークを利用して画像認識処理を試してみます.
画像認識や,本資料では扱いませんが音声認識などのニューラルネットワークモデルでは基本的に<strong>畳み込みニューラルネットワーク（Convolutional Neural Network, CNN）</strong>が用いられています.</p>
<p>基本的なニューラルネットワークは,入力層,AffineレイヤとReLUなどの活性化関数による隠れ層,Softmax関数などによる出力層から構成されていました.</p>
<p><img src="../images/ch14-NN-normal.png" /></p>
<p>全結合層（Affine Layer）は, 入力データ内の全てのニューロンが次の層の全てのニューロンと結合する構造を持っています. これは言い換えれば,全ての入力を1次元ベクトルに変換することを意味しています.しかし,例えば画像データは,縦・横・チャンネル方向(RGBなら3チャンネル)の三次元の構造を持ちます.
例えば, 28ピクセル×28ピクセルのグレースケール画像(1チャンネル)の場合は, <span class="math inline">\(28 \times 28 \times 1\)</span>という構造になります.</p>
<p>したがって,画像認識などの問題に対してAffine層を導入することは 画像や音声のようなデータの空間的構造を無視することになりますこれにより, データの位置や局所的な特徴を効果的に捉えることが困難になります.</p>
<p>そこでCNNでは<strong>畳み込み層(Convolution Layer)</strong>と<strong>プーリング層(Pooling Layer)</strong>を加えることでデータの空間的構造を適切に取り込みます.</p>
<p><img src="../images/ch14-CNN.png" /></p>
<div class="note">
<ul>
<li><h3 id="畳み込み層convolution-layer">畳み込み層（Convolution Layer）</h3></li>
</ul>
<p>畳み込み層は, 入力データ<span class="math inline">\(I\)</span>に対してフィルタ（カーネル）<span class="math inline">\(K\)</span> を適用して特徴マップ<span class="math inline">\(F\)</span>を生成します. 畳み込み演算は次の数式で表されます:</p>
<p><span class="math display">\[
F(x, y) = \sum_{i=1}^{m} \sum_{j=1}^{n} I(x+i, y+j) \cdot K(i, j)
\]</span></p>
<p>ここで:
<span class="math inline">\(I(x, y)\)</span> : 入力画像のピクセル値（例: グレースケール画像の場合0～255の値）,
<span class="math inline">\(K(i, j)\)</span> : フィルタ（カーネル）の要素,
<span class="math inline">\(m \times n\)</span> : フィルタのサイズ（例: <span class="math inline">\(3 \times 3\)</span> ）.</p>
<p>畳み込みの結果はフィルタが滑らかに適用されることで, 画像内の特徴（エッジや模様など）を抽出します.</p>
<p>例として,<span class="math inline">\(4 \times 4\)</span>のグレースケール画像を考えます.各要素は0～255のピクセル値を持ちます.</p>
<p>入力画像 I :</p>
<p><span class="math display">\[
I =
\begin{bmatrix}
1 &amp; 2 &amp; 3 &amp; 0 \\
0 &amp; 1 &amp; 2 &amp; 3 \\
1 &amp; 0 &amp; 1 &amp; 2 \\
2 &amp; 1 &amp; 0 &amp; 1
\end{bmatrix}
\]</span></p>
<p>フィルタ K :</p>
<p><span class="math display">\[
K =
\begin{bmatrix}
1 &amp; 0 &amp; -1 \\
1 &amp; 0 &amp; -1 \\
1 &amp; 0 &amp; -1
\end{bmatrix}
\]</span></p>
<p>このフィルタは<strong>垂直方向のエッジ(輪郭)</strong>を検出するためのカーネルとしてよく使われます.</p>
<h3 data-number="2.1" id="畳み込み演算のプロセス"><span class="header-section-number">2.1</span> 畳み込み演算のプロセス</h3>
<p>畳み込み演算では,フィルタ K を入力画像 I に適用し、以下の手順を繰り返します：</p>
<pre><code>1.  フィルタ  K  を入力画像  I  の一部（局所領域）に重ね合わせます.
2.  対応する要素同士を掛け算し,その結果を合計します.
3.  合計値を特徴マップ  F  の対応する位置に記録します.
4.  フィルタをストライド（移動量）分ずらして次の位置に移動し,同様の計算を繰り返します.</code></pre>
<p>ストライド: 1 （1ピクセルずつ移動）
出力特徴マップ F :
入力画像が <span class="math inline">\(4 \times 4\)</span> , フィルタサイズが <span class="math inline">\(3 \times 3\)</span> , ストライドが 1 の場合,出力特徴マップのサイズは以下で計算されます.</p>
<p><span class="math display">\[
F_{\text{Size}} = \left( I_{\text{Size}} - K_{\text{Size}} \right) / \text{Stride} + 1
\]</span></p>
<p><span class="math display">\[
F_{\text{Size}} = (4 - 3) / 1 + 1 = 2
\]</span></p>
<p>したがって,出力特徴マップ F のサイズは <span class="math inline">\(2 \times 2\)</span> になります.</p>
<p>畳み込み演算の計算手順</p>
<pre><code>ステップ1: フィルタを左上に適用</code></pre>
<p>入力画像の左上 <span class="math inline">\(3 \times 3\)</span> 領域：</p>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; 3 \\
0 &amp; 1 &amp; 2 \\
1 &amp; 0 &amp; 1
\end{bmatrix}
\]</span></p>
<p>フィルタ K を適用：</p>
<p><span class="math display">\[
F(1, 1) =
\begin{bmatrix}
1 &amp; 2 &amp; 3 \\
0 &amp; 1 &amp; 2 \\
1 &amp; 0 &amp; 1 \\
\end{bmatrix}
\cdot
\begin{bmatrix}
1 &amp; 0 &amp; -1 \\
1 &amp; 0 &amp; -1 \\
1 &amp; 0 &amp; -1
\end{bmatrix} \\
=
(1 \cdot 1) + (0 \cdot 2) + (-1 \cdot 3) +
(1 \cdot 0) + (0 \cdot 1) + (-1 \cdot 2) +
(1 \cdot 1) + (0 \cdot 0) + (-1 \cdot 1) \\
= 1 + 0 - 3 + 0 + 0 - 2 + 1 + 0 - 1 = -4
\]</span></p>
<p><img src="../images/ch14-kernel1.png" /></p>
<pre><code>ステップ2: フィルタを右に1つ移動</code></pre>
<p>次に,フィルタを右に1つ移動させて適用します。</p>
<p>入力画像の次の領域：</p>
<p><span class="math display">\[
\begin{bmatrix}
2 &amp; 3 &amp; 0 \\
1 &amp; 2 &amp; 3 \\
0 &amp; 1 &amp; 2
\end{bmatrix}
\]</span></p>
<p>フィルタ K を適用：
<span class="math display">\[
F(1, 2) =
\begin{bmatrix}
2 &amp; 3 &amp; 0 \\
1 &amp; 2 &amp; 3 \\
0 &amp; 1 &amp; 2 \\
\end{bmatrix}
\cdot
\begin{bmatrix}
1 &amp; 0 &amp; -1 \\
1 &amp; 0 &amp; -1 \\
1 &amp; 0 &amp; -1
\end{bmatrix}
= -2
\]</span></p>
<p><img src="../images/ch14-kernel2.png" /></p>
<p>ステップ3: フィルタを下に移動</p>
<p>フィルタを下に移動して適用します。</p>
<p>入力画像の次の領域：
<span class="math display">\[
\begin{bmatrix}
0 &amp; 1 &amp; 2 \\
1 &amp; 0 &amp; 1 \\
2 &amp; 1 &amp; 0
\end{bmatrix}
\]</span></p>
<p>フィルタ K を適用：</p>
<p><span class="math display">\[
F(2, 1) =
\begin{bmatrix}
0 &amp; 1 &amp; 2 \\
1 &amp; 0 &amp; 1 \\
2 &amp; 1 &amp; 0 \\
\end{bmatrix}
\cdot
\begin{bmatrix}
1 &amp; 0 &amp; -1 \\
1 &amp; 0 &amp; -1 \\
1 &amp; 0 &amp; -1
\end{bmatrix}
= 0
\]</span></p>
<p><img src="../images/ch14-kernel3.png" /></p>
<p>ステップ4: フィルタを右下に移動</p>
<p>最後に、フィルタを右下に移動して適用します。</p>
<p>入力画像の次の領域：
<span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; 3 \\
0 &amp; 1 &amp; 2 \\
1 &amp; 0 &amp; 1
\end{bmatrix}
\]</span></p>
<p>同様に計算すると：</p>
<p><span class="math display">\[
F(2, 1) =
\begin{bmatrix}
1 &amp; 2 &amp; 3 \\
0 &amp; 1 &amp; 2 \\
1 &amp; 0 &amp; 1
\end{bmatrix}
\cdot
\begin{bmatrix}
1 &amp; 0 &amp; -1 \\
1 &amp; 0 &amp; -1 \\
1 &amp; 0 &amp; -1
\end{bmatrix}
= -4
\]</span></p>
<p><img src="../images/ch14-kernel4.png" /></p>
<p>特徴マップの結果</p>
<p>畳み込み演算の結果として得られる特徴マップ F は次の通りです：</p>
<p><span class="math display">\[
F =
\begin{bmatrix}
-4 &amp; -2 \\
0  &amp; -2
\end{bmatrix}
\]</span></p>
<p><img src="../images/ch14-kernel5.png" /></p>
<p>実際にこの事例の画像にカーネルを適用すると以下のようになりますが,単純すぎて良くわからないので,我が家の犬の画像をグレースケールにしたものをにこのカーネルを適用したものが次の画像になります. 物体の垂直方向のエッジ(輪郭)のみが強調されていることが分かります.</p>
<p><img src="../images/ch14-After-Applying-Kernel.png" /></p>
<p><img src="../images/ch14-Vertical-Edge-Detection.png" /></p>
<p>ここでは,取り上げませんが,他の代表的なカーネルとして以下のようなものがあります.</p>
<p><img src="../images/ch14-Other-Kernels.png" /></p>
<h3 data-number="2.2" id="水平エッジ検出カーネル-horizontal-edge-detection-kernel"><span class="header-section-number">2.2</span> 水平エッジ検出カーネル (Horizontal Edge Detection Kernel)</h3>
<p><span class="math display">\[
K_{\text{horizontal}} =
\begin{bmatrix}
1 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 0 \\
-1 &amp; -1 &amp; -1
\end{bmatrix}
\]</span></p>
<p>このカーネルは、画像内の水平方向のエッジを検出します.
上部の値（ +1 ）と下部の値（ -1 ）が異なるため、明るい領域と暗い領域の境界を強調します.
例えば,地平線や階段の段差などの水平線を抽出するのに適しています.</p>
<h3 data-number="2.3" id="シャープ化カーネル-sharpen-kernel"><span class="header-section-number">2.3</span> シャープ化カーネル (Sharpen Kernel)</h3>
<p>行列表記:</p>
<p><span class="math display">\[
K_{\text{sharpen}} =
\begin{bmatrix}
0 &amp; -1 &amp; 0 \\
-1 &amp; 5 &amp; -1 \\
0 &amp; -1 &amp; 0
\end{bmatrix}
\]</span></p>
<p>中央の値（ 5 ）が高く, 周囲の値（ -1 ）が低いことで, 隣接するピクセルとの差を強調します.
これにより, 画像のエッジやディテールが際立ちます.
一般的に, エッジを目立たせたい場合やぼやけた画像を鮮明化する際に使用されます.</p>
<h3 data-number="2.4" id="ぼかしブラーカーネル-blur-kernel"><span class="header-section-number">2.4</span> ぼかし（ブラー）カーネル (Blur Kernel)</h3>
<p><span class="math display">\[
K_{\text{blur}} =
\frac{1}{9}
\begin{bmatrix}
1 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 1
\end{bmatrix}
\]</span></p>
<p>このカーネルは, 隣接するピクセルの平均値を計算して, 画像全体を滑らかにします.
ピクセル間の明るさの差を緩和し, ノイズの低減に役立ちます.
例えば, 背景の処理やノイズの軽減などに使用されます.</p>
<p>このようにフィルタの形状や内容に応じて異なる特徴(エッジ,模様など)を捉えることが可能です. この畳み込みフィルタの各セルの値が,これまでのニューラルネットワークにおける重み<span class="math inline">\(W\)</span>のように作用し,CNNではその値が学習の対称となります.</p>
</div>
<div class="note">
<ol start="3" type="1">
<li>プーリング層（Pooling Layer）</li>
</ol>
<p>プーリング層は, 特徴マップのサイズを縮小し, 計算量を減らすと同時に, 特徴の不変性を高める役割を持ちます.
例えば, <strong>最大プーリング（Max Pooling）</strong>は次の式で表されます:</p>
<p><span class="math display">\[
P(x, y) = \max_{i=1}^{m} \max_{j=1}^{n} F(x+i, y+j)
\]</span></p>
<p>ここで:
<span class="math inline">\(F(x, y)\)</span>: 入力特徴マップ,<span class="math inline">\(P(x, y)\)</span>: プーリング後の特徴マップ,<span class="math inline">\(m \times n\)</span>: プーリングウィンドウのサイズ（例: 2 ）.</p>
<p>最大プーリングは, 各ウィンドウ内の最大値を取得することで, 特徴の最も重要な部分を抽出します. 画像中のエッジや高輝度部分を強調するのに適しています.</p>
<p>例:
入力データ <span class="math inline">\(4 \times 4\)</span> の行列に対し, <span class="math inline">\(2 \times 2\)</span> のウィンドウサイズで最大プーリングを適用します.</p>
<p>入力行列:</p>
<p><span class="math display">\[
I =
\begin{bmatrix}
1 &amp; 3 &amp; 2 &amp; 1 \\
4 &amp; 6 &amp; 5 &amp; 0 \\
7 &amp; 8 &amp; 9 &amp; 2 \\
3 &amp; 4 &amp; 1 &amp; 6
\end{bmatrix}
\]</span></p>
<p>手順:
各 <span class="math inline">\(2 \times 2\)</span> のウィンドウ内の最大値を取り, 縮小された行列を生成します.
1. 最初の <span class="math inline">\(2 \times 2\)</span> ウィンドウ:
<span class="math display">\[
\begin{bmatrix}
1 &amp; 3 \\
4 &amp; 6
\end{bmatrix}
\quad \text{最大値: } 6
\]</span></p>
<p><span class="math display">\[
\begin{bmatrix}
2 &amp; 1 \\
5 &amp; 0
\end{bmatrix}
\quad \text{最大値: } 5
\]</span></p>
<p><span class="math display">\[
\begin{bmatrix}
7 &amp; 8 \\
3 &amp; 4
\end{bmatrix}
\quad \text{最大値: } 8
\]</span></p>
<p><span class="math display">\[
\begin{bmatrix}
9 &amp; 2 \\
1 &amp; 6
\end{bmatrix}
\quad \text{最大値: } 9
\]</span></p>
<p>出力行列:</p>
<p><span class="math display">\[
P_{\text{max}} =
\begin{bmatrix}
6 &amp; 5 \\
8 &amp; 9
\end{bmatrix}
\]</span></p>
</div>
<p>CNNの全体的なデータフローを数式でまとめると次のようになります:</p>
<div class="note">
<pre><code>1.  畳み込み層:</code></pre>
<p><span class="math display">\[
F^{(l)} = f(W^{(l)} * F^{(l-1)} + b^{(l)})
\]</span></p>
<p><span class="math inline">\(W^{(l)}\)</span> : 畳み込みフィルタ（重み）,<span class="math inline">\(F^{(l-1)}\)</span> : 前層の特徴マップ,<span class="math inline">\(b^{(l)}\)</span> : バイアス,<span class="math inline">\(f\)</span> : 活性化関数（例: ReLU）.</p>
<pre><code>2.  プーリング層:</code></pre>
<p><span class="math display">\[
P^{(l)} = \text{Pooling}(F^{(l)})
\]</span></p>
<pre><code>3.  全結合層:</code></pre>
<p><span class="math display">\[
Y = \text{Softmax}(WX + B)
\]</span></p>
<p>W : 全結合層の重み行列,X : プーリング層の出力,B : バイアス.</p>
</div>
<p>このように, CNNは畳み込み層で特徴を抽出し, プーリング層でデータの次元を縮小し, 全結合層で最終的な予測を行います. これらの操作が連続的に行われることで, 画像や音声などのデータの複雑なパターンを学習することが可能になります.</p>
<h3 data-number="2.5" id="代表的なcnnモデル"><span class="header-section-number">2.5</span> 代表的なCNNモデル</h3>
<p>CNNを利用した主な画像認識モデルの歴史は以下のようにまとめられます.</p>
<table>
<colgroup>
<col style="width: 3%" />
<col style="width: 11%" />
<col style="width: 51%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="header">
<th>年代</th>
<th>モデル名</th>
<th>特徴・概要</th>
<th>主な貢献や革新点</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1998</td>
<td>LeNet</td>
<td>手書き数字認識に使われた初期のCNNモデル. 主にMNISTデータセットで使用.</td>
<td>畳み込み層とプーリング層を使用した初期の画像認識モデル.</td>
</tr>
<tr class="even">
<td>2012</td>
<td>AlexNet</td>
<td>ImageNetで初めて畳み込みニューラルネットワークを使用し,トップ5エラー率を大幅に改善.</td>
<td>ReLU活性化関数の使用や,GPUによるトレーニングの導入.</td>
</tr>
<tr class="odd">
<td>2014</td>
<td>VGGNet</td>
<td>小さな3x3のフィルタを多層に積み重ねたアーキテクチャ.VGG16とVGG19が特に有名.</td>
<td>モデルの深さが精度に大きく寄与することを示す.</td>
</tr>
<tr class="even">
<td>2014</td>
<td>GoogLeNet (Inception)</td>
<td>“Inception Module”を採用し,計算効率と精度を両立.</td>
<td>異なるサイズの畳み込みフィルタを同時に適用するInceptionモジュール.</td>
</tr>
<tr class="odd">
<td>2015</td>
<td>ResNet</td>
<td>残差ブロックを使用し,非常に深いネットワークのトレーニングを可能に.ImageNetで優勝.</td>
<td>152層の深いネットワークで,勾配消失問題を解決.</td>
</tr>
<tr class="even">
<td>2016</td>
<td>DenseNet</td>
<td>各層がすべての前層からの入力を受け取る密結合アーキテクチャ.</td>
<td>パラメータ効率が良く,勾配の流れが改善される.</td>
</tr>
<tr class="odd">
<td>2017</td>
<td>Xception</td>
<td>畳み込みの代わりに「深さ方向の畳み込み（Depthwise Separable Convolutions）」を使用.</td>
<td>計算コストの削減と精度の向上.</td>
</tr>
<tr class="even">
<td>2017</td>
<td>MobileNet</td>
<td>軽量かつ効率的なCNNアーキテクチャ.モバイルデバイス向けに最適化.</td>
<td>計算量を削減し,モバイル環境でのリアルタイム推論を可能に.</td>
</tr>
<tr class="odd">
<td>2020</td>
<td>Vision Transformer (ViT)</td>
<td>画像をパッチに分割し,トランスフォーマーアーキテクチャを使用したモデル.</td>
<td>トランスフォーマーモデルが画像認識タスクでも有効であることを示す.</td>
</tr>
<tr class="even">
<td>2021</td>
<td>Swin Transformer</td>
<td>階層的なトランスフォーマーアーキテクチャで,局所的な窓（ウィンドウ）を用いた画像認識モデル.</td>
<td>トランスフォーマーのスケーラビリティを改善し,高い精度を達成.</td>
</tr>
<tr class="odd">
<td>2022</td>
<td>ConvNeXt</td>
<td>Vision Transformerのアイデアを取り入れた畳み込みネットワークの進化版.</td>
<td>畳み込みベースのモデルが再び最先端性能を達成できることを示す.</td>
</tr>
</tbody>
</table>
<p>今回は,事例としてConvNeXtを利用した画像認識を実行してみます.</p>
<p><a href="https://github.com/facebookresearch/ConvNeXt">ConvNeXt</a>は,Meta(旧Facebook)によって発表されたモデルで,Vision Transformer (ViT) を参考にしつつResNet（Residual Network）を基盤として作られたCNNです.</p>
<p>PythonのCNNのライブラリはいくつか存在しますが,ConvNeXtは,Metaによって開発された<code>PyTorch</code>上で実装されています.</p>
<h3 data-number="2.6" id="顔による年齢識別"><span class="header-section-number">2.6</span> 顔による年齢識別</h3>
<p>事例として顔画像からの年齢識別を行ってみましょう. データとして,16歳から62歳までの2,000人の有名人の160,000以上の画像が含まれるデータセット<a href="http://bcsiriuschen.github.io/CARC/">Cross-Age Celebrity Dataset (CACD)</a>を用います.</p>
<figure>
<img src="../images/CACD.png" alt="The dataset metadata" />
<figcaption aria-hidden="true">The dataset metadata</figcaption>
</figure>
<p><code>The dataset metadata only can be downloaded</code>をクリックしてメタデータを, <code>Original face images (detected and croped by openCV face detector) can be downloaded</code>をクリックして画像データをダウンロードしてください(3Gあるので通信環境に注意).</p>
<p><code>CACD2000.tar.gz</code>は展開して,<code>celebrity2000_meta.mat</code>とともにプログラムを配置するディレクトリ内の<code>data</code>ディレクトリに保存しておきましょう.</p>
<h4 data-number="2.6.1" id="画像ファイルの形式"><span class="header-section-number">2.6.1</span> 画像ファイルの形式</h4>
<p>機械学習において利用されるラベル付き画像データの形式はいくつかあるが,CACDのような<code>.mat</code>ファイル,画像とCSVなどのラベルの組み合わせ,ラベル名フォルダ別の画像ファイルなどのパターンが存在する. いずれにも対応できるようにしておく必要があるが, この資料では最も単純な最後のラベル別に名前がつけられたフォルダに保存された画像ファイルを扱う.</p>
<p>先ほどダウンロードした<code>celebrity2000_meta.mat</code>は,メタデータのみが含まれており,画像は別になっています.メタデータに従って,年齢別に画像をフォルダに保存してみましょう.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> ls</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="ex">face_image.py</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="ex">data</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> ls <span class="ex">data</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="ex">CACD2000</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="ex">celebrity2000_meta.mat</span></span></code></pre></div>
<div class="note">
<ul>
<li><h3 id="matファイル"><code>.mat</code>ファイル</h3>
<ul>
<li>MATLABのファイル</li>
<li>基本的には <code>scipy</code> を利用して読み込む.</li>
<li>フォーマット形式がMATLAB <code>v7.3</code>の場合には,<code>HDF5</code>を扱うライブラリ<code>h5py</code>を利用する.</li>
<li><code>HDF5(Hierarchical Data Froamt version 5)</code>はディレクトリ構造に似た階層型のデータフォーマット</li>
</ul></li>
</ul>
</div>
<p>まずは,<code>h5py</code>を利用して<code>celebrity2000_meta.mat</code>を読み込み,中身を確認してみましょう.</p>
<div class="warn">
<p>以下のライブラリが必要になるので <code>pip install</code>しておいてください.</p>
<ul>
<li><code>pytorch</code>
<ul>
<li>CNN用ライブラリ(PyTorch)</li>
</ul></li>
<li><code>torchvision</code>
<ul>
<li>PyTorchの画像,動画処理用ライブラリ</li>
</ul></li>
<li><code>scipy</code></li>
<li><code>h5py</code></li>
<li><code>pillow</code>
<ul>
<li>画像処理用ライブラリ</li>
</ul></li>
<li><code>shutil</code>
<ul>
<li>ファイル操作用ライブラリ</li>
</ul></li>
</ul>
</div>
<div class="sourceCode" id="cb13"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> h5py <span class="co">#HDF5を扱うライブラリ</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image <span class="co">#画像の表示/保存/書き込みなどを扱うライブラリ</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.io</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co">#画像データの保存先</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>image_dir <span class="op">=</span> <span class="st">'data/CACD2000'</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co"># .matファイルの読み込み（古い形式の場合）</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co">## 辞書型として読み込まれる</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="bu">file</span> <span class="op">=</span> scipy.io.loadmat(<span class="st">'data/celebrity2000_meta.mat'</span>)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 辞書のKeyを表示する</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'keys:'</span>,<span class="bu">file</span>.keys())</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co"># &gt;&gt;&gt; dict_keys(['__header__', '__version__', '__globals__', 'celebrityData', 'celebrityImageData'])</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="co">#celebrityImageDataの確認</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">file</span>[<span class="st">'celebrityImageData'</span>])</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="co">&quot;&quot;&quot;</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="co">[[(array([[53],</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="co">         [53],</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="co">         [53],</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="co">         ...,</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="co">         [23],</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="co">         [23],</span></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a><span class="co">         [23]], dtype=uint8), array([[   1],</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="co">         [   1],</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a><span class="co">         [   1],</span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a><span class="co">         ...,</span></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a><span class="co">         [2000],</span></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a><span class="co">         [2000],</span></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a><span class="co">         [2000]], dtype=uint16), array([[2004],</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a><span class="co">         [2004],</span></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a><span class="co">         [2004],</span></span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a><span class="co">         ...,</span></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a><span class="co">         [2013],</span></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a><span class="co">         [2013],</span></span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a><span class="co">         [2013]], dtype=uint16), array([], shape=(0, 0), dtype=uint8), array([[ 1],</span></span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a><span class="co">         [ 1],</span></span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a><span class="co">         [ 1],</span></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a><span class="co">         ...,</span></span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a><span class="co">         [50],</span></span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a><span class="co">         [50],</span></span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a><span class="co">         [50]], dtype=uint8), array([[1],</span></span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a><span class="co">         [1],</span></span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a><span class="co">         [1],</span></span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a><span class="co">         ...,</span></span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a><span class="co">         [0],</span></span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a><span class="co">         [0],</span></span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a><span class="co">         [0]], dtype=uint8), array([[1951],</span></span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a><span class="co">         [1951],</span></span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a><span class="co">         [1951],</span></span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a><span class="co">         ...,</span></span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a><span class="co">         [1990],</span></span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a><span class="co">         [1990],</span></span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a><span class="co">         [1990]], dtype=uint16), array([[array(['53_Robin_Williams_0001.jpg'], dtype='&lt;U26')],</span></span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a><span class="co">         [array(['53_Robin_Williams_0002.jpg'], dtype='&lt;U26')],</span></span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a><span class="co">         [array(['53_Robin_Williams_0003.jpg'], dtype='&lt;U26')],</span></span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a><span class="co">         ...,</span></span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a><span class="co">         [array(['23_Katie_Findlay_0011.jpg'], dtype='&lt;U25')],</span></span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a><span class="co">         [array(['23_Katie_Findlay_0012.jpg'], dtype='&lt;U25')],</span></span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a><span class="co">         [array(['23_Katie_Findlay_0013.jpg'], dtype='&lt;U25')]], dtype=object))                ]]</span></span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a><span class="co">&quot;&quot;&quot;</span></span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a><span class="co"># 7個目に画像のファイル名が入っているので</span></span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a><span class="co"># celebrityImageDataから画像ファイル名を抽出</span></span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>image_data <span class="op">=</span> <span class="bu">file</span>[<span class="st">'celebrityImageData'</span>]</span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a>jpg_files <span class="op">=</span> [<span class="bu">str</span>(image_name[<span class="dv">0</span>][<span class="dv">0</span>]) <span class="cf">for</span> image_name <span class="kw">in</span> image_data[<span class="dv">0</span>][<span class="dv">0</span>][<span class="dv">7</span>]]</span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a><span class="co"># 抽出された.jpgファイル名のリストを上から10個表示</span></span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(jpg_files[:<span class="dv">10</span>])</span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a><span class="co"># 画像データの取得と表示</span></span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a><span class="co">## 名前データを利用して画像をいくつか開いてみます.</span></span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> jpg_files[:<span class="dv">10</span>]:</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>    img_path <span class="op">=</span> os.path.join(image_dir, n)  <span class="co"># パスを結合し,ファイル名を取得</span></span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> os.path.exists(img_path):</span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)  <span class="co"># 画像ファイルを開く</span></span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a>        img.show()  <span class="co"># 画像を表示</span></span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Image file not found: </span><span class="sc">{</span>img_path<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&gt;&gt;&gt; 画像が表示されます</span></span></code></pre></div>
<div class="warn">
<ul>
<li>HDF5の利用例</li>
</ul>
<p><code>CACD</code>データのうち一番上の<code>The dataset metadata and features used in this paper</code>からダウンロードできる<code>celebrity2000.mat</code>は,<code>HDF5</code>のデータとなっているため,<code>scipy</code>で読み込んでみるとエラーが出ます.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="bu">file</span> <span class="op">=</span> scipy.io.loadmat(<span class="st">'data/celebrity2000.mat'</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co">&quot;&quot;&quot;</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co">Traceback (most recent call last):</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co">  File &quot;/Users/akagi/Desktop/face_image.py&quot;, line 86, in &lt;module&gt;</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co">    file = scipy.io.loadmat('data/celebrity2000.mat')</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co">           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">  File &quot;/Users/akagi/.pyenv/versions/3.12.3/lib/python3.12/site-packages/scipy/io/matlab/_mio.py&quot;, line 226, in loadmat</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co">    MR, _ = mat_reader_factory(f, **kwargs)</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co">            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co">  File &quot;/Users/akagi/.pyenv/versions/3.12.3/lib/python3.12/site-packages/scipy/io/matlab/_mio.py&quot;, line 80, in mat_reader_factory</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co">    raise NotImplementedError('Please use HDF reader for matlab v7.3 '</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co">NotImplementedError: Please use HDF reader for matlab v7.3 files, e.g. h5py</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="co">&quot;&quot;&quot;</span></span></code></pre></div>
<p>今回は<code>celebrity2000_meta.mat</code>を利用するので必要ありませんが,試しに同じように画像を表示してみましょう.</p>
<p><code>HDF5</code>は多重の辞書型ような構造をしており,<code>key</code>によってデータにアクセスできます.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> h5py <span class="co">#HDF5を扱うライブラリ</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image <span class="co">#画像の表示/保存/書き込みなどを扱うライブラリ</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># .matファイル(HDF5)の読み込み</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> h5py.File(<span class="st">'data/celebrity2000.mat'</span>, <span class="st">'r'</span>) <span class="im">as</span> <span class="bu">file</span>:</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># List all keys in the .mat file</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'keys:'</span>,<span class="bu">list</span>(<span class="bu">file</span>.keys()))</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># &gt;&gt;&gt; keys: ['#refs#', 'celebrityData', 'celebrityImageData']</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">## ラベルの確認</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'DataKeys:'</span>,<span class="bu">file</span>[<span class="st">'celebrityImageData'</span>].keys())</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># &gt;&gt;&gt; DataKeys: &lt;KeysViewHDF5 ['age', 'birth', 'feature', 'identity', 'lfw', 'name', 'rank', 'year']&gt;</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 年齢データの確認</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'age:'</span>,<span class="bu">file</span>[<span class="st">'celebrityImageData'</span>][<span class="st">'age'</span>])</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># &gt;&gt;&gt; age: &lt;HDF5 dataset &quot;age&quot;: shape (1, 163446), type &quot;&lt;f8&quot;&gt;</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'age:'</span>,<span class="bu">file</span>[<span class="st">'celebrityImageData'</span>][<span class="st">'age'</span>][<span class="dv">0</span>])</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># &gt;&gt;&gt; age: [53. 53. 53. ... 23. 23. 23.]</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 名前データの確認</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'name:'</span>,<span class="bu">file</span>[<span class="st">'celebrityImageData'</span>][<span class="st">'name'</span>])</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># &gt;&gt;&gt; name: &lt;HDF5 dataset &quot;name&quot;: shape (1, 163446), type &quot;|O&quot;&gt;</span></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'name:'</span>,<span class="bu">file</span>[<span class="st">'celebrityImageData'</span>][<span class="st">'name'</span>][<span class="dv">0</span>])</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># &gt;&gt;&gt; name: [&lt;HDF5 object reference&gt; &lt;HDF5 object reference&gt; &lt;HDF5 object reference&gt;</span></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">#... &lt;HDF5 object reference&gt; &lt;HDF5 object reference&gt;</span></span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&lt;HDF5 object reference&gt;]</span></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ↑ &lt;HDF5 object reference&gt;は他のHDF5オブジェクトへの参照 #refs#に入っている.</span></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># nameデータを参照して表示</span></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>    name_references <span class="op">=</span> <span class="bu">file</span>[<span class="st">'celebrityImageData'</span>][<span class="st">'name'</span>][<span class="dv">0</span>]</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>    names <span class="op">=</span> []</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ref <span class="kw">in</span> name_references:</span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>        name <span class="op">=</span> <span class="bu">file</span>[ref][()].tobytes().decode(<span class="st">'utf-16'</span>)  <span class="co"># utf-16でデコード</span></span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>        names.append(name)</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 最初の10件の名前を表示</span></span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'names:'</span>, names[:<span class="dv">10</span>])</span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># names: ['53_Robin_Williams_0001.jpg'</span></span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># , '53_Robin_Williams_0002.jpg'</span></span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># , '53_Robin_Williams_0003.jpg'</span></span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># , '53_Robin_Williams_0004.jpg'</span></span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># , '53_Robin_Williams_0005.jpg'</span></span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># , '53_Robin_Williams_0006.jpg'</span></span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># , '53_Robin_Williams_0007.jpg'</span></span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># , '53_Robin_Williams_0009.jpg'</span></span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># , '53_Robin_Williams_0010.jpg'</span></span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># , '53_Robin_Williams_0011.jpg']</span></span>
<span id="cb15-50"><a href="#cb15-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-51"><a href="#cb15-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 画像データの取得と表示</span></span>
<span id="cb15-52"><a href="#cb15-52" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 名前データを利用して画像をいくつか開いてみます.</span></span>
<span id="cb15-53"><a href="#cb15-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> n <span class="kw">in</span> names[:<span class="dv">10</span>]:</span>
<span id="cb15-54"><a href="#cb15-54" aria-hidden="true" tabindex="-1"></a>        img_path <span class="op">=</span> os.path.join(image_dir, n)  <span class="co"># パスを結合し,ファイル名を取得</span></span>
<span id="cb15-55"><a href="#cb15-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-56"><a href="#cb15-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> os.path.exists(img_path):</span>
<span id="cb15-57"><a href="#cb15-57" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)  <span class="co"># 画像ファイルを開く</span></span>
<span id="cb15-58"><a href="#cb15-58" aria-hidden="true" tabindex="-1"></a>            img.show()  <span class="co"># 画像を表示</span></span>
<span id="cb15-59"><a href="#cb15-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb15-60"><a href="#cb15-60" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Image file not found: </span><span class="sc">{</span>img_path<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb15-61"><a href="#cb15-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># &gt;&gt;&gt; 画像が表示される</span></span></code></pre></div>
<p>同じ用にデータを抽出できることが確認できます.</p>
</div>
<p>それでは,<code>celebrity2000_meta.mat</code>から年齢別にフォルダを分けて画像を保存してみます.年齢区分は,<code>10</code>,<code>20</code>,…,<code>100</code>としてみましょう. 画像ファイル名の先頭の数字が年齢を表しているので,そちらを利用しても構いませんが,せっかくなのでメタデータを利用してみましょう. 年齢は<code>image_data[0][0][0]</code>に入っているようです.</p>
<p>研究であれば画像データの枚数は多いほど良いですが, 今回は一通りの流れを体験してみることが目的なので学生の環境でも利用しやすいように各年代200枚だけコピーします.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.io</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 画像ディレクトリの設定</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>image_dir <span class="op">=</span> <span class="st">'data/CACD2000'</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>output_dir <span class="op">=</span> <span class="st">'data/sorted_images'</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co"># .matファイルの読み込み</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="bu">file</span> <span class="op">=</span> scipy.io.loadmat(<span class="st">'data/celebrity2000_meta.mat'</span>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co"># celebrityImageDataから年齢と画像ファイル名を抽出</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>image_data <span class="op">=</span> <span class="bu">file</span>[<span class="st">'celebrityImageData'</span>]</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 年齢情報</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>ages <span class="op">=</span> image_data[<span class="dv">0</span>][<span class="dv">0</span>][<span class="dv">0</span>].flatten()</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 画像ファイル名</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>jpg_files <span class="op">=</span> [<span class="bu">str</span>(image_name[<span class="dv">0</span>][<span class="dv">0</span>]) <span class="cf">for</span> image_name <span class="kw">in</span> image_data[<span class="dv">0</span>][<span class="dv">0</span>][<span class="dv">7</span>]]</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 年齢と画像ファイルをペアにする</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>age_image_pairs <span class="op">=</span> <span class="bu">list</span>(<span class="bu">zip</span>(ages, jpg_files))</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a><span class="co"># 年代ごとの画像カウント</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>age_group_counts <span class="op">=</span> defaultdict(<span class="bu">int</span>)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a><span class="co"># 年齢別に画像をシャッフル</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>random.shuffle(age_image_pairs)</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a><span class="co"># 年齢別のフォルダに画像をコピー（各年代最大200枚）</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> age, jpg_file <span class="kw">in</span> age_image_pairs:</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>    age_group <span class="op">=</span> (age <span class="op">//</span> <span class="dv">10</span>) <span class="op">*</span> <span class="dv">10</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> age_group <span class="op">&gt;</span> <span class="dv">100</span>:</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>        age_group <span class="op">=</span> <span class="dv">100</span>  <span class="co"># 100代以上は100代フォルダに保存</span></span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 各年代ごとに200枚までコピー</span></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> age_group_counts[age_group] <span class="op">&lt;</span> <span class="dv">200</span>:</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>        folder_path <span class="op">=</span> os.path.join(output_dir, <span class="ss">f'</span><span class="sc">{</span>age_group<span class="sc">}</span><span class="ss">s'</span>)</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>        os.makedirs(folder_path, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>        src_path <span class="op">=</span> os.path.join(image_dir, jpg_file)</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>        dst_path <span class="op">=</span> os.path.join(folder_path, jpg_file)</span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>        shutil.copy(src_path, dst_path)</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>        age_group_counts[age_group] <span class="op">+=</span> <span class="dv">1</span></span></code></pre></div>
<p>結果を確認してみます.</p>
<div class="warn">
<p>Shell コマンドにおける<code>|</code> は<code>パイプ</code>といって <code>head -20</code>は先頭20個のみ
<code>|</code> の左側のコマンドによる標準出力を右側のコマンドに渡すことができます.</p>
<p>今回は<code>ls data/sorted_images/10s</code>で表示される結果の,先頭20個のみを表示しています.</p>
</div>
<div class="sourceCode" id="cb17"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> ls <span class="ex">data/sorted_images</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="ex">10s</span> 20s 30s 40s 50s 60s</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> ls <span class="ex">data/sorted_images/10s</span> <span class="kw">|</span><span class="fu">head</span> <span class="at">-20</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Alison_Pill_0001.jpg</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Alison_Pill_0002.jpg</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Alison_Pill_0003.jpg</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Alison_Pill_0005.jpg</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Alison_Pill_0006.jpg</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Alison_Pill_0007.jpg</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Alison_Pill_0009.jpg</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Alison_Pill_0011.jpg</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Amanda_Seyfried_0001.jpg</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Amanda_Seyfried_0002.jpg</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Amanda_Seyfried_0004.jpg</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Amanda_Seyfried_0005.jpg</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Amanda_Seyfried_0007.jpg</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Amanda_Seyfried_0008.jpg</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Amanda_Seyfried_0010.jpg</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Amanda_Seyfried_0011.jpg</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Amanda_Seyfried_0013.jpg</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Amanda_Seyfried_0014.jpg</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Anna_Kendrick_0002.jpg</span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a><span class="ex">19_Anna_Kendrick_0008.jpg</span></span></code></pre></div>
<p>データには10代から60代までのみが含まれていたようです. 各フォルダの中身を確認してもちゃんと保存できていることがわかりますね.</p>
<p>機械学習モデルの性能を評価するためには,学習に利用する訓練用データと,学習の結果を判定するテスト用データに分ける必要があります. 続いて,学習用とテスト用でフォルダに分割してみましょう.</p>
<p>今回は200枚の画像のうち8割(160枚)を学習用,2割(40枚)をテスト用のデータとして利用します.</p>
<p>学習データの分割には, 指定した割合でデータを分割してくれる<code>sklearn</code>の<code>train_test_split</code>を用います.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> <span class="st">'data/sorted_images'</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>output_dir <span class="op">=</span> <span class="st">'data/sorted_images_split'</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 画像ファイルのパスを収集し,年齢別に分類</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>age_groups <span class="op">=</span> [<span class="st">'10s'</span>, <span class="st">'20s'</span>, <span class="st">'30s'</span>, <span class="st">'40s'</span>, <span class="st">'50s'</span>, <span class="st">'60s'</span>]</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> age_group <span class="kw">in</span> age_groups:</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> os.listdir(os.path.join(data_dir, age_group))</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    train_images, val_images <span class="op">=</span> train_test_split(images</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>                                               ,test_size<span class="op">=</span><span class="fl">0.2</span> <span class="co">#2割をテスト用データにする</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>                                               , random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    train_dir <span class="op">=</span> os.path.join(output_dir, <span class="st">'train'</span>, age_group)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    val_dir <span class="op">=</span> os.path.join(output_dir, <span class="st">'val'</span>, age_group)</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    os.makedirs(train_dir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    os.makedirs(val_dir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> image <span class="kw">in</span> train_images:</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>        shutil.copy(os.path.join(data_dir, age_group, image), os.path.join(train_dir, image))</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> image <span class="kw">in</span> val_images:</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>        shutil.copy(os.path.join(data_dir, age_group, image), os.path.join(val_dir, image))</span></code></pre></div>
<p>以下のような形でデータが保存されていることを確認しましょう.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="ex">data/sorted_images_split</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> train</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>      ├── 10s</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>      ├── 20s</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>      ├── 30s</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>      ├── 40s</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>      ├── 50s</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>      └── 60s</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> val</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> 10s</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> 20s</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> 30s</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> 40s</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> 50s</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        <span class="ex">└──</span> 60s</span></code></pre></div>
<h4 data-number="2.6.2" id="画像認識の実施"><span class="header-section-number">2.6.2</span> 画像認識の実施</h4>
<p>CNNを利用した学習を行うにあたって,コード内で扱われる基本的な概念を説明します.</p>
<div class="note">
<ul>
<li><h3 id="ハイパーパラメータ"><strong>ハイパーパラメータ</strong></h3>
機械学習では,プログラムが自動で学習を進めてくれますが,良い性能を達成するためには人間がいくつかのパラメータを設定する必要があります. また,様々な改善手法があるため,モデルが上手く学習できない場合には,それらを経験によって調整していく必要があります.</li>
</ul>
<p>本資料では,それらの細かな内容にはあまり踏み込みませんが,以下,基本的な処理やパラメータに関して説明します.</p>
<ul>
<li><h3 id="前処理data-augmentation"><strong>前処理(Data Augmentation)</strong></h3>
<p>学習を行うために,画像サイズや色の内容と無関係の情報を減らし,画像を統一のフォーマットに揃えます.</p>
<ul>
<li><strong>リサイズ (Resize)</strong></li>
</ul>
<p>画像のサイズを揃えます.今回は224 × 224 ピクセルに統一します.</p>
<ul>
<li><strong>画像反転 (Horizontal Flip)</strong></li>
</ul>
<p>水平方向に画像を反転させることで,データに多様性を加えます.</p>
<ul>
<li><strong>テンソル(Tensor)変換</strong></li>
</ul>
<p>データの多次元配列を<strong>Tensor</strong>と呼びます. データを,複数の行列によるテンソルに変換することで効率的に学習を行います.
例えば,画像の場合は,高さ,幅,チャンネル数(RGBカラー等の色)の3次元テンソルとして表現します.</p>
<ul>
<li><strong>正規化(Normalize)</strong></li>
</ul>
<p>画像データを特定の範囲や分布に変換してモデルが効率的に学習できるようにする手法を正規化といいます. CNNで学習される画像データは,0から255の範囲のピクセル値(色や濃淡の数値)で表現されますが,ばらつきが大きすぎると学習が不安定になるため,0から1の範囲に変換します.</p></li>
</ul>
<div class="warn">
<p>なお,正規化に利用されてい平均や標準偏差の値(<code>[0.485, 0.456, 0.406]</code>)などは,ConvNeXtの学習に用いられている,大規模画像データベース<a href="https://www.image-net.org">ImageNet</a>の平均及び標準偏差です.</p>
<p>実際には,<strong>使用するデータの</strong>平均及び標準偏差を用いる必要がありますが今回はあくまで事例の紹介であり利用する画像データ毎に変更する必要があるので,便宜的にこの値を利用しています.</p>
<p>テスト用の実装などでは,すべて<code>0.5</code>にするなどもよく行われていますが,本来は変更すべき値であることに注意しましょう.</p>
</div>
<p>該当部分(全体のインデントは省略)</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># データ変換（前処理）</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>data_transforms <span class="op">=</span> {</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'train'</span>: transforms.Compose([</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>        transforms.Resize((<span class="dv">224</span>, <span class="dv">224</span>)),     <span class="co">#画像のリサイズ</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>        transforms.RandomHorizontalFlip(), <span class="co">#画像をランダムに反転</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),             <span class="co">#テンソル(多次元配列)に変換</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize(mean<span class="op">=</span>[<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>]</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>                            ,std<span class="op">=</span>[<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>]), <span class="co">#正規化(本来は値を変更する必要あり.</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    ]),</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'val'</span>: transforms.Compose([</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>        transforms.Resize((<span class="dv">224</span>, <span class="dv">224</span>)),</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize([<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>]</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>                            ,[<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>]),</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    ]),</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>この他にも画像の彩度や光度の調整, ランダム回転,スケーリングなど,様々な前処理手法があり,状況に応じて使い分ける必要があります.</p>
<ul>
<li><h3 id="バッチbatch処理"><strong>バッチ(batch)処理</strong></h3></li>
</ul>
<p>CNNでは学習用のデータ全てを一度に学習するとメモリを大量に消費するため,データを分割して学習を行います. そのような分割処理を<strong>バッチ処理</strong>といいます.</p>
<p>分割された一つあたりのデータの数を<strong>バッチサイズ</strong>といいます. バッチサイズが32個の場合は32個の(今回の場合は画像ファイル)を同時に処理します.</p>
<p>また,バッチ処理ではバッチ毎に並列処理を行うため速度面でも,効率的な学習が行えます.</p>
<ul>
<li><h3 id="エポックepoch数"><strong>エポック(epoch)数</strong></h3></li>
</ul>
<p>CNNではモデルの性能を高めるために同じデータセットを何度も繰り返して学習することがあります.その際に,データを1巡して学習する回数を,<strong>エポック数</strong>といいます. 例えば, 10エポックの場合は,160枚の画像を10回学習することになります.</p>
<p>エポック数を増やすと一般的に性能が高まりすが,多すぎる場合には<strong>過学習</strong>が起きるので,エポック数を変更してある程度誤差がが安定する適切なエポック数を見つけることが重要です.</p>
<p>また,本資料では利用していませんが,PyTorchには自動で過学習を防ぐために途中で学習を打ち切る<code>Early Stopping</code>用の機能などもあります.</p>
<p>以下のコードでは,エポック数ごとの誤差を記録して,グラフを出力するようになっています.</p>
<ul>
<li><h3 id="損失関数loss-function"><strong>損失関数(Loss Function)</strong></h3>
学習したモデルの性能を調べるために, モデルの予測と実際のラベルとの誤差(損失)を計算するための関数を<strong>損失関数</strong>といいます.
基本的に, 損失関数で求められた誤差が大きいほど,モデルの正確性が劣っていることを示します.</li>
</ul>
<p>損失関数にはいくつかの種類がありますが,今回は<strong>クロスエントロピー損失(Coross-Entoropy Loss)</strong>を利用します. これは,予測された確率分布と実際のラベルの分布の不一致度を計測しています.</p>
<ul>
<li><h3 id="オプティマイザoptimizer"><strong>オプティマイザ(Optimizer)</strong></h3>
損失関数の値を最小化するために,どのようにモデルのパラメータを更新するかを決定するアルゴリズムを<strong>オプティマイザ</strong>といいます.</li>
</ul>
<p>基本的には,損失関数によって求められた誤差の勾配(パラメータに対する誤差の微分)を計算してエポック毎に誤差が減る方向にパラメータを調整します.</p>
<p>よく使われるアルゴリズムには,<strong>SGD(Stochastic Gradient Descent)</strong>や,<strong>Adam(Adaptive Moment Estimation)</strong>などがあります.</p>
<p>特定のオプティマイザで上手くいかない場合はパラメータや,アルゴリズムを変更します.</p>
<p>該当部分(全体のインデントは省略)</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 損失関数とオプティマイザ</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> nn.CrossEntropyLoss() <span class="co">#クロスエントロピー損失</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> optim.Adam(model.parameters() <span class="co">#Adam</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>                          ,lr<span class="op">=</span><span class="fl">0.0001</span>) <span class="co">#Learning rate (学習率)</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#SGDを利用する場合</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)</span></span></code></pre></div>
<ul>
<li><h3 id="学習率learning-rate"><strong>学習率(learning rate)</strong></h3>
機械学習モデルが重み（パラメータ）を更新する際に,その更新幅を決めるハイパーパラメータを<strong>学習率(learning rate)</strong>といいます. モデルの訓練時に,誤差（損失）を最小化するために重みを調整していきますが,学習率はその調整量を決定します.</li>
</ul>
<p>学習率が大きい場合には1回の更新で重みが大きく変わるため,学習が速く進むことがありますが,最適な解にたどり着く前に振動してしまったり,安定せずに解に収束しないことがあります.</p>
<p>学習率が小さい場合には,更新幅が小さいので,安定して最適解に近づく可能性が高まりますが,学習に時間がかかりすぎてしまい,訓練が遅くなることがあります.</p>
<p>一般的には<code>0.001</code>程度から初めて変更していくのが良いとされていますが,以下の事例では調整の結果<code>0.0001</code>を採用しています.</p>
<p>このような特性から<strong>SGD</strong>などのオプティマイザでは学習率の設定が非常に重要であり,オプティマイザとは別に学習率を調整するスケジューリングなどの技法が利用されることがあります. 一方で,<strong>Adam</strong>は,ある程度学習率を自動で調整するため,SGDほど,学習率の初期値が結果に影響しないという特徴があります.</p>
<ul>
<li><h3 id="ランダムシードrandom-seed"><strong>ランダムシード(Random Seed)</strong></h3>
CNNは,初期値(重みの設定),学習データのシャッフル,オプティマイザなどで乱数(ランダムな値)を利用しているので,実行毎に異なる結果が出てくることが一般的です.</li>
</ul>
<p>毎回異なる値が生成されるように乱数は,通常CPU時間(プログラムを実行したときのPC内部の時間)などの外部の情報を利用します.</p>
<p>従って, 通常この資料と同じデータを利用して,同じコードを実行しても結果は異なります.
ただし,それでは検証などにおいて不便な場合があります.
また,講義用資料としても不便なので,同じ乱数を利用してできるだけ同じ結果を再現する必要があります.</p>
<p>そこで,以下のコードでは利用する乱数を固定するために,乱数を生成するための情報<strong>ランダムシード</strong>を固定しています.</p>
<p>シード値は適当な数値で構いません. 西暦(<code>2024</code>)や,適当な連番(<code>1234</code>など),特定のミームの数字(<code>42</code>など)が用いられます.</p>
<p>(ただし,実行環境などの違いにより,ランダムシードを固定しても完全に同じ値にはなりません.)</p>
<p><code>set_seed()</code>行をコメントアウトすることで,通常の乱数が利用できるようになるので,研究に利用する場合などには適宜変更してください.</p>
<p>該当部分(全体のインデントは省略)</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 乱数シードを設定</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_seed(seed):</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(seed)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    np.random.seed(seed)              <span class="co"># Numpy用の乱数シードを設定</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    random.seed(seed)                 <span class="co"># Pythonの標準乱数シードを設定</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 再現性を完全に保証するために以下も設定（ただし、若干のパフォーマンス低下の可能性あり）</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    torch.backends.cudnn.deterministic <span class="op">=</span> <span class="va">True</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    torch.backends.cudnn.benchmark <span class="op">=</span> <span class="va">False</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> main():</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># シードを設定する</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">#(自分の研究でやる場合は以下の行は消しても問題ない.)</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    set_seed(<span class="dv">42</span>)</span></code></pre></div>
<ul>
<li><h3 id="cuda-compute-unified-device-architecture"><strong>CUDA (Compute Unified Device Architecture)</strong></h3>
機械学習では, GPUを用いた計算を行うことが一般的です. 特にPyTorchなどでは,NVIDIAが開発したGPU向けの並列コンピューティングプラットフォームである<strong>CUDA (Compute Unified Device Architecture)</strong>を前提にライブラリが開発されています.
従って, <strong>CUDA</strong>が搭載されたPCでは,<strong>CUDA</strong>を利用することが望ましいです.</li>
</ul>
<p>しかし,例えば現在のMacOSは<strong>CUDA</strong>に対応しておらず, WindowsPCでもコストなどの観点から異なるGPUが搭載されている場合があります.</p>
<p>M1〜M3などのApple Siliconを搭載したMacでは,PyTorchの実行にあたり<strong>CUDA</strong>の代わりに<strong>MPS (Metal Performance Shaders)</strong>が利用可能です.</p>
<p>PyTorchでは<code>torch.device()</code>で利用するデバイスを設定できますが,以下のコードでは, CUDA, MPSが利用できる場合にはそれらを利用し,利用できない場合にはCPUを利用しています.</p>
<p>該当部分(全体のインデントは省略)</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.backends.mps.is_available():</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">&quot;mps&quot;</span>) <span class="co">#Mac GPU</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> torch.cuda.is_available():</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">&quot;cuda:0&quot;</span>) <span class="co">#Win GPU</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">&quot;cpu&quot;</span>) <span class="co">#CPU</span></span></code></pre></div>
</div>
<p>これから,先程分割した画像を利用してConvNeXtによる学習を行い, PCAとt-sneで2次元へ次元削減した後,ラベルごとの特徴を可視化してみます.</p>
<div class="warn">
<p>以下のコードを実行すると,PCのスペックによっては10分以上ほぼ全てのCPU/GPUが使用されます.
他の不必要なアプリを閉じて,時間に余裕があるときに電源に繋いだ状態で実行しましょう.
このコードは学生のローカル環境でも動くようになっていますが,上手くいかない場合はGoogle Colaboratory上で試してみましょう.</p>
</div>
<div class="warn">
<p>コードを実行して以下のようなWarningが表示される場合,個別の環境によって対処が異なるので教員に
相談してください.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="ex">Found</span> Intel OpenMP <span class="er">(</span><span class="st">'libiomp'</span><span class="kw">)</span> <span class="ex">and</span> LLVM OpenMP <span class="er">(</span><span class="st">'libomp'</span><span class="kw">)</span> <span class="ex">loaded</span> at</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="ex">the</span> same time. Both libraries are known to be incompatible and this</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="ex">can</span> cause random crashes or deadlocks on Linux when loaded in the</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="ex">same</span> Python program.</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="ex">Using</span> threadpoolctl may cause crashes or deadlocks. For more</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="ex">information</span> and possible workarounds, please see</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span class="ex">https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md</span></span></code></pre></div>
</div>
<p>コードの全体像は以下のようになります.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 次元削減用</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co"># CNN用</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms, models</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.models <span class="im">import</span> ConvNeXt_Tiny_Weights</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a><span class="co">#学習した特徴量を抽出する</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_features(model, dataloader, device):</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>    features <span class="op">=</span> []</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>    labels_list <span class="op">=</span> []</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> inputs, labels <span class="kw">in</span> dataloader:</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> inputs.to(device)</span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> labels.to(device)</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(inputs)</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>            features.append(outputs.cpu())</span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>            labels_list.append(labels.cpu())</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>    features <span class="op">=</span> torch.cat(features, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> torch.cat(labels_list, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> features, labels</span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a><span class="co"># t-SNEによる次元圧縮と散布図の描画</span></span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_tsne(train_features, train_labels, path):</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># train_featuresとtrain_labelsをnumpyに変換</span></span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>    features_np <span class="op">=</span> train_features.numpy()</span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a>    labels_np <span class="op">=</span> train_labels.numpy()</span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># t-SNEによる次元圧縮 (2次元)</span></span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a>    tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a>    features_2d <span class="op">=</span> tsne.fit_transform(features_np)</span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 散布図の描画</span></span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb25-52"><a href="#cb25-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-53"><a href="#cb25-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 各ラベルに基づいて色分けしてプロット</span></span>
<span id="cb25-54"><a href="#cb25-54" aria-hidden="true" tabindex="-1"></a>    num_classes <span class="op">=</span> <span class="bu">len</span>(np.unique(labels_np))  <span class="co"># クラス数を取得</span></span>
<span id="cb25-55"><a href="#cb25-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> label <span class="kw">in</span> np.unique(labels_np):</span>
<span id="cb25-56"><a href="#cb25-56" aria-hidden="true" tabindex="-1"></a>        indices <span class="op">=</span> np.where(labels_np <span class="op">==</span> label)</span>
<span id="cb25-57"><a href="#cb25-57" aria-hidden="true" tabindex="-1"></a>        plt.scatter(features_2d[indices, <span class="dv">0</span>]</span>
<span id="cb25-58"><a href="#cb25-58" aria-hidden="true" tabindex="-1"></a>                   ,features_2d[indices, <span class="dv">1</span>]</span>
<span id="cb25-59"><a href="#cb25-59" aria-hidden="true" tabindex="-1"></a>                   ,label<span class="op">=</span><span class="ss">f'</span><span class="sc">{</span>(label <span class="op">+</span> <span class="dv">1</span>) <span class="op">*</span> <span class="dv">10</span><span class="sc">}</span><span class="ss">s'</span></span>
<span id="cb25-60"><a href="#cb25-60" aria-hidden="true" tabindex="-1"></a>                   ,alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb25-61"><a href="#cb25-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-62"><a href="#cb25-62" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'t-SNE of Train Features'</span>)</span>
<span id="cb25-63"><a href="#cb25-63" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'t-SNE Component 1'</span>)</span>
<span id="cb25-64"><a href="#cb25-64" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'t-SNE Component 2'</span>)</span>
<span id="cb25-65"><a href="#cb25-65" aria-hidden="true" tabindex="-1"></a>    plt.legend(title<span class="op">=</span><span class="st">&quot;Age Group&quot;</span>)</span>
<span id="cb25-66"><a href="#cb25-66" aria-hidden="true" tabindex="-1"></a>    plt.grid(<span class="va">True</span>)</span>
<span id="cb25-67"><a href="#cb25-67" aria-hidden="true" tabindex="-1"></a>    plt.savefig(path)</span>
<span id="cb25-68"><a href="#cb25-68" aria-hidden="true" tabindex="-1"></a>    plt.close()</span>
<span id="cb25-69"><a href="#cb25-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-70"><a href="#cb25-70" aria-hidden="true" tabindex="-1"></a><span class="co"># PCAによる次元圧縮と散布図の描画</span></span>
<span id="cb25-71"><a href="#cb25-71" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_pca(train_features, train_labels, path):</span>
<span id="cb25-72"><a href="#cb25-72" aria-hidden="true" tabindex="-1"></a>    <span class="co"># train_featuresとtrain_labelsをnumpyに変換</span></span>
<span id="cb25-73"><a href="#cb25-73" aria-hidden="true" tabindex="-1"></a>    features_np <span class="op">=</span> train_features.numpy()</span>
<span id="cb25-74"><a href="#cb25-74" aria-hidden="true" tabindex="-1"></a>    labels_np <span class="op">=</span> train_labels.numpy()</span>
<span id="cb25-75"><a href="#cb25-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-76"><a href="#cb25-76" aria-hidden="true" tabindex="-1"></a>    <span class="co"># PCAによる次元圧縮 (2次元)</span></span>
<span id="cb25-77"><a href="#cb25-77" aria-hidden="true" tabindex="-1"></a>    pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb25-78"><a href="#cb25-78" aria-hidden="true" tabindex="-1"></a>    features_2d <span class="op">=</span> pca.fit_transform(features_np)</span>
<span id="cb25-79"><a href="#cb25-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-80"><a href="#cb25-80" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 散布図の描画</span></span>
<span id="cb25-81"><a href="#cb25-81" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb25-82"><a href="#cb25-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-83"><a href="#cb25-83" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 各ラベルに基づいて色分けしてプロット</span></span>
<span id="cb25-84"><a href="#cb25-84" aria-hidden="true" tabindex="-1"></a>    num_classes <span class="op">=</span> <span class="bu">len</span>(np.unique(labels_np))  <span class="co"># クラス数を取得</span></span>
<span id="cb25-85"><a href="#cb25-85" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> label <span class="kw">in</span> np.unique(labels_np):</span>
<span id="cb25-86"><a href="#cb25-86" aria-hidden="true" tabindex="-1"></a>        indices <span class="op">=</span> np.where(labels_np <span class="op">==</span> label)</span>
<span id="cb25-87"><a href="#cb25-87" aria-hidden="true" tabindex="-1"></a>        plt.scatter(features_2d[indices, <span class="dv">0</span>]</span>
<span id="cb25-88"><a href="#cb25-88" aria-hidden="true" tabindex="-1"></a>                   ,features_2d[indices, <span class="dv">1</span>]</span>
<span id="cb25-89"><a href="#cb25-89" aria-hidden="true" tabindex="-1"></a>                   ,label<span class="op">=</span><span class="ss">f'</span><span class="sc">{</span>(label <span class="op">+</span> <span class="dv">1</span>) <span class="op">*</span> <span class="dv">10</span><span class="sc">}</span><span class="ss">s'</span></span>
<span id="cb25-90"><a href="#cb25-90" aria-hidden="true" tabindex="-1"></a>                   ,alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb25-91"><a href="#cb25-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-92"><a href="#cb25-92" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'PCA of Train Features'</span>)</span>
<span id="cb25-93"><a href="#cb25-93" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'PCA Component 1'</span>)</span>
<span id="cb25-94"><a href="#cb25-94" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'PCA Component 2'</span>)</span>
<span id="cb25-95"><a href="#cb25-95" aria-hidden="true" tabindex="-1"></a>    plt.legend(title<span class="op">=</span><span class="st">&quot;Age Group&quot;</span>)</span>
<span id="cb25-96"><a href="#cb25-96" aria-hidden="true" tabindex="-1"></a>    plt.grid(<span class="va">True</span>)</span>
<span id="cb25-97"><a href="#cb25-97" aria-hidden="true" tabindex="-1"></a>    plt.savefig(path)</span>
<span id="cb25-98"><a href="#cb25-98" aria-hidden="true" tabindex="-1"></a>    plt.close()</span>
<span id="cb25-99"><a href="#cb25-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-100"><a href="#cb25-100" aria-hidden="true" tabindex="-1"></a><span class="co"># 乱数シードを設定</span></span>
<span id="cb25-101"><a href="#cb25-101" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_seed(seed):</span>
<span id="cb25-102"><a href="#cb25-102" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(seed)</span>
<span id="cb25-103"><a href="#cb25-103" aria-hidden="true" tabindex="-1"></a>    np.random.seed(seed)              <span class="co"># Numpy用の乱数シードを設定</span></span>
<span id="cb25-104"><a href="#cb25-104" aria-hidden="true" tabindex="-1"></a>    random.seed(seed)                 <span class="co"># Pythonの標準乱数シードを設定</span></span>
<span id="cb25-105"><a href="#cb25-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-106"><a href="#cb25-106" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 再現性を完全に保証するために以下も設定（ただし、若干のパフォーマンス低下の可能性あり）</span></span>
<span id="cb25-107"><a href="#cb25-107" aria-hidden="true" tabindex="-1"></a>    torch.backends.cudnn.deterministic <span class="op">=</span> <span class="va">True</span></span>
<span id="cb25-108"><a href="#cb25-108" aria-hidden="true" tabindex="-1"></a>    torch.backends.cudnn.benchmark <span class="op">=</span> <span class="va">False</span></span>
<span id="cb25-109"><a href="#cb25-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-110"><a href="#cb25-110" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> main():</span>
<span id="cb25-111"><a href="#cb25-111" aria-hidden="true" tabindex="-1"></a>    <span class="co"># シードを設定する</span></span>
<span id="cb25-112"><a href="#cb25-112" aria-hidden="true" tabindex="-1"></a>    <span class="co">#(自分の研究でやる場合は以下の行は消しても問題ない.)</span></span>
<span id="cb25-113"><a href="#cb25-113" aria-hidden="true" tabindex="-1"></a>    set_seed(<span class="dv">2024</span>)</span>
<span id="cb25-114"><a href="#cb25-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-115"><a href="#cb25-115" aria-hidden="true" tabindex="-1"></a>    <span class="co"># データのディレクトリ設定</span></span>
<span id="cb25-116"><a href="#cb25-116" aria-hidden="true" tabindex="-1"></a>    data_dir <span class="op">=</span> <span class="st">'data/sorted_images_split'</span></span>
<span id="cb25-117"><a href="#cb25-117" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb25-118"><a href="#cb25-118" aria-hidden="true" tabindex="-1"></a>    num_epochs <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb25-119"><a href="#cb25-119" aria-hidden="true" tabindex="-1"></a>    num_classes <span class="op">=</span> <span class="dv">6</span>  <span class="co"># 10代, 20代, ..., 60代</span></span>
<span id="cb25-120"><a href="#cb25-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-121"><a href="#cb25-121" aria-hidden="true" tabindex="-1"></a>    <span class="co"># データ変換（前処理）</span></span>
<span id="cb25-122"><a href="#cb25-122" aria-hidden="true" tabindex="-1"></a>    data_transforms <span class="op">=</span> {</span>
<span id="cb25-123"><a href="#cb25-123" aria-hidden="true" tabindex="-1"></a>        <span class="st">'train'</span>: transforms.Compose([</span>
<span id="cb25-124"><a href="#cb25-124" aria-hidden="true" tabindex="-1"></a>            transforms.Resize((<span class="dv">224</span>, <span class="dv">224</span>)),     <span class="co">#画像のリサイズ</span></span>
<span id="cb25-125"><a href="#cb25-125" aria-hidden="true" tabindex="-1"></a>            transforms.RandomHorizontalFlip(), <span class="co">#画像をランダムに反転</span></span>
<span id="cb25-126"><a href="#cb25-126" aria-hidden="true" tabindex="-1"></a>            transforms.ColorJitter(brightness<span class="op">=</span><span class="fl">0.2</span>, contrast<span class="op">=</span><span class="fl">0.2</span>),  <span class="co"># 色調変化</span></span>
<span id="cb25-127"><a href="#cb25-127" aria-hidden="true" tabindex="-1"></a>            transforms.ToTensor(),             <span class="co">#テンソル(多次元配列)に変換</span></span>
<span id="cb25-128"><a href="#cb25-128" aria-hidden="true" tabindex="-1"></a>            transforms.Normalize(mean<span class="op">=</span>[<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>]</span>
<span id="cb25-129"><a href="#cb25-129" aria-hidden="true" tabindex="-1"></a>                                ,std<span class="op">=</span>[<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>]), <span class="co">#正規化(本来は値を変更する必要あり.</span></span>
<span id="cb25-130"><a href="#cb25-130" aria-hidden="true" tabindex="-1"></a>        ]),</span>
<span id="cb25-131"><a href="#cb25-131" aria-hidden="true" tabindex="-1"></a>        <span class="st">'val'</span>: transforms.Compose([</span>
<span id="cb25-132"><a href="#cb25-132" aria-hidden="true" tabindex="-1"></a>            transforms.Resize((<span class="dv">224</span>, <span class="dv">224</span>)),</span>
<span id="cb25-133"><a href="#cb25-133" aria-hidden="true" tabindex="-1"></a>            transforms.ToTensor(),</span>
<span id="cb25-134"><a href="#cb25-134" aria-hidden="true" tabindex="-1"></a>            transforms.Normalize([<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>]</span>
<span id="cb25-135"><a href="#cb25-135" aria-hidden="true" tabindex="-1"></a>                                ,[<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>]),</span>
<span id="cb25-136"><a href="#cb25-136" aria-hidden="true" tabindex="-1"></a>        ]),</span>
<span id="cb25-137"><a href="#cb25-137" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb25-138"><a href="#cb25-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-139"><a href="#cb25-139" aria-hidden="true" tabindex="-1"></a>    <span class="co"># データセットの読み込み</span></span>
<span id="cb25-140"><a href="#cb25-140" aria-hidden="true" tabindex="-1"></a>    image_datasets <span class="op">=</span> {x: datasets.ImageFolder(os.path.join(data_dir, x),</span>
<span id="cb25-141"><a href="#cb25-141" aria-hidden="true" tabindex="-1"></a>                                              data_transforms[x])</span>
<span id="cb25-142"><a href="#cb25-142" aria-hidden="true" tabindex="-1"></a>                      <span class="cf">for</span> x <span class="kw">in</span> [<span class="st">'train'</span>, <span class="st">'val'</span>]}</span>
<span id="cb25-143"><a href="#cb25-143" aria-hidden="true" tabindex="-1"></a>    dataloaders <span class="op">=</span> {x: DataLoader(image_datasets[x]</span>
<span id="cb25-144"><a href="#cb25-144" aria-hidden="true" tabindex="-1"></a>                                ,batch_size<span class="op">=</span>batch_size</span>
<span id="cb25-145"><a href="#cb25-145" aria-hidden="true" tabindex="-1"></a>                                ,shuffle<span class="op">=</span><span class="va">True</span></span>
<span id="cb25-146"><a href="#cb25-146" aria-hidden="true" tabindex="-1"></a>                                ,num_workers<span class="op">=</span><span class="dv">4</span>) <span class="co">#使用するCore数</span></span>
<span id="cb25-147"><a href="#cb25-147" aria-hidden="true" tabindex="-1"></a>                   <span class="cf">for</span> x <span class="kw">in</span> [<span class="st">'train'</span>, <span class="st">'val'</span>]}</span>
<span id="cb25-148"><a href="#cb25-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-149"><a href="#cb25-149" aria-hidden="true" tabindex="-1"></a>    <span class="co"># デバイス設定</span></span>
<span id="cb25-150"><a href="#cb25-150" aria-hidden="true" tabindex="-1"></a>    <span class="co">#GPUが利用できる場合はGPUを使う,そうでない場合はCPUを計算に利用します.</span></span>
<span id="cb25-151"><a href="#cb25-151" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> torch.backends.mps.is_available():</span>
<span id="cb25-152"><a href="#cb25-152" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> torch.device(<span class="st">&quot;mps&quot;</span>) <span class="co">#Mac GPU</span></span>
<span id="cb25-153"><a href="#cb25-153" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> torch.cuda.is_available():</span>
<span id="cb25-154"><a href="#cb25-154" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> torch.device(<span class="st">&quot;cuda:0&quot;</span>) <span class="co">#Win GPU</span></span>
<span id="cb25-155"><a href="#cb25-155" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb25-156"><a href="#cb25-156" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> torch.device(<span class="st">&quot;cpu&quot;</span>) <span class="co">#CPU</span></span>
<span id="cb25-157"><a href="#cb25-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-158"><a href="#cb25-158" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Using device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb25-159"><a href="#cb25-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-160"><a href="#cb25-160" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ConvNextモデルの読み込みとカスタマイズ</span></span>
<span id="cb25-161"><a href="#cb25-161" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">=</span> ConvNeXt_Tiny_Weights.IMAGENET1K_V1  <span class="co"># 最新の重みを指定</span></span>
<span id="cb25-162"><a href="#cb25-162" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> models.convnext_tiny(weights<span class="op">=</span>weights)  <span class="co"># ConvNextの小さいモデルを使用</span></span>
<span id="cb25-163"><a href="#cb25-163" aria-hidden="true" tabindex="-1"></a>    <span class="co">#モデル分類層の最終層(第3層(0,1,2番目))の入力特徴量を取得</span></span>
<span id="cb25-164"><a href="#cb25-164" aria-hidden="true" tabindex="-1"></a>    num_ftrs <span class="op">=</span> model.classifier[<span class="dv">2</span>].in_features</span>
<span id="cb25-165"><a href="#cb25-165" aria-hidden="true" tabindex="-1"></a>    <span class="co">#既に学習されたモデルではクラス数がことなるので ,入力特徴量の数(num_ftrs)はそのまま</span></span>
<span id="cb25-166"><a href="#cb25-166" aria-hidden="true" tabindex="-1"></a>    <span class="co">#出力をクラス数に変更</span></span>
<span id="cb25-167"><a href="#cb25-167" aria-hidden="true" tabindex="-1"></a>    model.classifier[<span class="dv">2</span>] <span class="op">=</span> nn.Linear(num_ftrs, num_classes)</span>
<span id="cb25-168"><a href="#cb25-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-169"><a href="#cb25-169" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> model.to(device)</span>
<span id="cb25-170"><a href="#cb25-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-171"><a href="#cb25-171" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 損失関数とオプティマイザ</span></span>
<span id="cb25-172"><a href="#cb25-172" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> nn.CrossEntropyLoss() <span class="co">#クロスエントロピー損失</span></span>
<span id="cb25-173"><a href="#cb25-173" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> optim.Adam(model.parameters() <span class="co">#Adam</span></span>
<span id="cb25-174"><a href="#cb25-174" aria-hidden="true" tabindex="-1"></a>                          ,lr<span class="op">=</span><span class="fl">0.0001</span>) <span class="co">#Learning rate (学習率)</span></span>
<span id="cb25-175"><a href="#cb25-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-176"><a href="#cb25-176" aria-hidden="true" tabindex="-1"></a>    <span class="co">#SGDを利用する場合</span></span>
<span id="cb25-177"><a href="#cb25-177" aria-hidden="true" tabindex="-1"></a>    <span class="co">#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)</span></span>
<span id="cb25-178"><a href="#cb25-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-179"><a href="#cb25-179" aria-hidden="true" tabindex="-1"></a>    <span class="co">#結果の記録用</span></span>
<span id="cb25-180"><a href="#cb25-180" aria-hidden="true" tabindex="-1"></a>    train_losses <span class="op">=</span> []</span>
<span id="cb25-181"><a href="#cb25-181" aria-hidden="true" tabindex="-1"></a>    train_accuracies <span class="op">=</span> []</span>
<span id="cb25-182"><a href="#cb25-182" aria-hidden="true" tabindex="-1"></a>    val_losses <span class="op">=</span> []</span>
<span id="cb25-183"><a href="#cb25-183" aria-hidden="true" tabindex="-1"></a>    val_accuracies <span class="op">=</span> []</span>
<span id="cb25-184"><a href="#cb25-184" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb25-185"><a href="#cb25-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-186"><a href="#cb25-186" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 学習ループ</span></span>
<span id="cb25-187"><a href="#cb25-187" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb25-188"><a href="#cb25-188" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>num_epochs<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb25-189"><a href="#cb25-189" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'-'</span> <span class="op">*</span> <span class="dv">10</span>)</span>
<span id="cb25-190"><a href="#cb25-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-191"><a href="#cb25-191" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> phase <span class="kw">in</span> [<span class="st">'train'</span>, <span class="st">'val'</span>]:</span>
<span id="cb25-192"><a href="#cb25-192" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> phase <span class="op">==</span> <span class="st">'train'</span>:</span>
<span id="cb25-193"><a href="#cb25-193" aria-hidden="true" tabindex="-1"></a>                model.train()</span>
<span id="cb25-194"><a href="#cb25-194" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb25-195"><a href="#cb25-195" aria-hidden="true" tabindex="-1"></a>                model.<span class="bu">eval</span>()</span>
<span id="cb25-196"><a href="#cb25-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-197"><a href="#cb25-197" aria-hidden="true" tabindex="-1"></a>            running_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb25-198"><a href="#cb25-198" aria-hidden="true" tabindex="-1"></a>            running_corrects <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb25-199"><a href="#cb25-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-200"><a href="#cb25-200" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> inputs, labels <span class="kw">in</span> dataloaders[phase]:</span>
<span id="cb25-201"><a href="#cb25-201" aria-hidden="true" tabindex="-1"></a>                inputs <span class="op">=</span> inputs.to(device)</span>
<span id="cb25-202"><a href="#cb25-202" aria-hidden="true" tabindex="-1"></a>                labels <span class="op">=</span> labels.to(device)</span>
<span id="cb25-203"><a href="#cb25-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-204"><a href="#cb25-204" aria-hidden="true" tabindex="-1"></a>                optimizer.zero_grad()</span>
<span id="cb25-205"><a href="#cb25-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-206"><a href="#cb25-206" aria-hidden="true" tabindex="-1"></a>                <span class="cf">with</span> torch.set_grad_enabled(phase <span class="op">==</span> <span class="st">'train'</span>):</span>
<span id="cb25-207"><a href="#cb25-207" aria-hidden="true" tabindex="-1"></a>                    outputs <span class="op">=</span> model(inputs)</span>
<span id="cb25-208"><a href="#cb25-208" aria-hidden="true" tabindex="-1"></a>                    _, preds <span class="op">=</span> torch.<span class="bu">max</span>(outputs, <span class="dv">1</span>)</span>
<span id="cb25-209"><a href="#cb25-209" aria-hidden="true" tabindex="-1"></a>                    loss <span class="op">=</span> criterion(outputs, labels)</span>
<span id="cb25-210"><a href="#cb25-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-211"><a href="#cb25-211" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> phase <span class="op">==</span> <span class="st">'train'</span>:</span>
<span id="cb25-212"><a href="#cb25-212" aria-hidden="true" tabindex="-1"></a>                        loss.backward()</span>
<span id="cb25-213"><a href="#cb25-213" aria-hidden="true" tabindex="-1"></a>                        optimizer.step()</span>
<span id="cb25-214"><a href="#cb25-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-215"><a href="#cb25-215" aria-hidden="true" tabindex="-1"></a>                running_loss <span class="op">+=</span> loss.item() <span class="op">*</span> inputs.size(<span class="dv">0</span>)</span>
<span id="cb25-216"><a href="#cb25-216" aria-hidden="true" tabindex="-1"></a>                running_corrects <span class="op">+=</span> torch.<span class="bu">sum</span>(preds <span class="op">==</span> labels.data)</span>
<span id="cb25-217"><a href="#cb25-217" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> phase <span class="op">==</span> <span class="st">'val'</span>:  <span class="co"># バリデーション時に予測と実際のラベルを保存</span></span>
<span id="cb25-218"><a href="#cb25-218" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(labels)):</span>
<span id="cb25-219"><a href="#cb25-219" aria-hidden="true" tabindex="-1"></a>                        results.append({</span>
<span id="cb25-220"><a href="#cb25-220" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'epoch'</span>: epoch <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb25-221"><a href="#cb25-221" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'pred'</span>: preds[i].item(),</span>
<span id="cb25-222"><a href="#cb25-222" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'acctual'</span>: labels[i].item()</span>
<span id="cb25-223"><a href="#cb25-223" aria-hidden="true" tabindex="-1"></a>                        })</span>
<span id="cb25-224"><a href="#cb25-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-225"><a href="#cb25-225" aria-hidden="true" tabindex="-1"></a>            epoch_loss <span class="op">=</span> running_loss <span class="op">/</span> <span class="bu">len</span>(image_datasets[phase])</span>
<span id="cb25-226"><a href="#cb25-226" aria-hidden="true" tabindex="-1"></a>            epoch_acc <span class="op">=</span> running_corrects.<span class="bu">float</span>() <span class="op">/</span> <span class="bu">len</span>(image_datasets[phase])</span>
<span id="cb25-227"><a href="#cb25-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-228"><a href="#cb25-228" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>phase<span class="sc">}</span><span class="ss"> Loss: </span><span class="sc">{</span>epoch_loss<span class="sc">:.4f}</span><span class="ss"> Acc: </span><span class="sc">{</span>epoch_acc<span class="sc">:.4f}</span><span class="ss">'</span>)</span>
<span id="cb25-229"><a href="#cb25-229" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> phase <span class="op">==</span> <span class="st">'train'</span>:</span>
<span id="cb25-230"><a href="#cb25-230" aria-hidden="true" tabindex="-1"></a>                train_losses.append(epoch_loss)</span>
<span id="cb25-231"><a href="#cb25-231" aria-hidden="true" tabindex="-1"></a>                train_accuracies.append(epoch_acc.item())</span>
<span id="cb25-232"><a href="#cb25-232" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb25-233"><a href="#cb25-233" aria-hidden="true" tabindex="-1"></a>                val_losses.append(epoch_loss)</span>
<span id="cb25-234"><a href="#cb25-234" aria-hidden="true" tabindex="-1"></a>                val_accuracies.append(epoch_acc.item())</span>
<span id="cb25-235"><a href="#cb25-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-236"><a href="#cb25-236" aria-hidden="true" tabindex="-1"></a>    <span class="co">#結果の表示</span></span>
<span id="cb25-237"><a href="#cb25-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-238"><a href="#cb25-238" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Training complete'</span>)</span>
<span id="cb25-239"><a href="#cb25-239" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Training Losses: &quot;</span>, train_losses)</span>
<span id="cb25-240"><a href="#cb25-240" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Training Accuracies: &quot;</span>, train_accuracies)</span>
<span id="cb25-241"><a href="#cb25-241" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Validation Losses: &quot;</span>, val_losses)</span>
<span id="cb25-242"><a href="#cb25-242" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Validation Accuracies: &quot;</span>, val_accuracies)</span>
<span id="cb25-243"><a href="#cb25-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-244"><a href="#cb25-244" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 結果を可視化してCSVファイルに保存</span></span>
<span id="cb25-245"><a href="#cb25-245" aria-hidden="true" tabindex="-1"></a>    loss_acc <span class="op">=</span> pd.DataFrame({<span class="st">'train_losses'</span>:train_losses</span>
<span id="cb25-246"><a href="#cb25-246" aria-hidden="true" tabindex="-1"></a>                            ,<span class="st">'train_accuracies'</span>:train_accuracies</span>
<span id="cb25-247"><a href="#cb25-247" aria-hidden="true" tabindex="-1"></a>                            ,<span class="st">'val_losses'</span>:val_losses</span>
<span id="cb25-248"><a href="#cb25-248" aria-hidden="true" tabindex="-1"></a>                            ,<span class="st">'val_accuracies'</span>:val_accuracies})</span>
<span id="cb25-249"><a href="#cb25-249" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Losses'</span>)</span>
<span id="cb25-250"><a href="#cb25-250" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb25-251"><a href="#cb25-251" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Losses'</span>)</span>
<span id="cb25-252"><a href="#cb25-252" aria-hidden="true" tabindex="-1"></a>    plt.plot(np.arange(num_epochs),loss_acc[<span class="st">'train_losses'</span>],c<span class="op">=</span><span class="st">'r'</span>,label<span class="op">=</span><span class="st">'train_losses'</span>)</span>
<span id="cb25-253"><a href="#cb25-253" aria-hidden="true" tabindex="-1"></a>    plt.plot(np.arange(num_epochs),loss_acc[<span class="st">'val_losses'</span>],c<span class="op">=</span><span class="st">'b'</span>,label<span class="op">=</span><span class="st">'val_losses'</span>)</span>
<span id="cb25-254"><a href="#cb25-254" aria-hidden="true" tabindex="-1"></a>    plt.grid(<span class="va">True</span>)</span>
<span id="cb25-255"><a href="#cb25-255" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb25-256"><a href="#cb25-256" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="st">'data/result/convnext_loss.png'</span>)</span>
<span id="cb25-257"><a href="#cb25-257" aria-hidden="true" tabindex="-1"></a>    plt.close()</span>
<span id="cb25-258"><a href="#cb25-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-259"><a href="#cb25-259" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Accuracies'</span>)</span>
<span id="cb25-260"><a href="#cb25-260" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb25-261"><a href="#cb25-261" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Accuracies'</span>)</span>
<span id="cb25-262"><a href="#cb25-262" aria-hidden="true" tabindex="-1"></a>    plt.plot(np.arange(num_epochs),loss_acc[<span class="st">'train_accuracies'</span>],c<span class="op">=</span><span class="st">'r'</span>,label<span class="op">=</span><span class="st">'train_accuracies'</span>)</span>
<span id="cb25-263"><a href="#cb25-263" aria-hidden="true" tabindex="-1"></a>    plt.plot(np.arange(num_epochs),loss_acc[<span class="st">'val_accuracies'</span>],c<span class="op">=</span><span class="st">'b'</span>,label<span class="op">=</span><span class="st">'val_accuracies'</span>)</span>
<span id="cb25-264"><a href="#cb25-264" aria-hidden="true" tabindex="-1"></a>    plt.grid(<span class="va">True</span>)</span>
<span id="cb25-265"><a href="#cb25-265" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb25-266"><a href="#cb25-266" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="st">'data/result/convnext_acc.png'</span>)</span>
<span id="cb25-267"><a href="#cb25-267" aria-hidden="true" tabindex="-1"></a>    plt.close()</span>
<span id="cb25-268"><a href="#cb25-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-269"><a href="#cb25-269" aria-hidden="true" tabindex="-1"></a>    loss_acc.to_csv(<span class="st">'data/result/convnext_loss_acc.csv'</span></span>
<span id="cb25-270"><a href="#cb25-270" aria-hidden="true" tabindex="-1"></a>                   ,encoding<span class="op">=</span><span class="st">'utf_8_sig'</span>)</span>
<span id="cb25-271"><a href="#cb25-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-272"><a href="#cb25-272" aria-hidden="true" tabindex="-1"></a>    results_df <span class="op">=</span> pd.DataFrame(results)</span>
<span id="cb25-273"><a href="#cb25-273" aria-hidden="true" tabindex="-1"></a>    result_max_epochs <span class="op">=</span> results_df[results_df[<span class="st">'epoch'</span>] <span class="op">==</span> num_epochs]</span>
<span id="cb25-274"><a href="#cb25-274" aria-hidden="true" tabindex="-1"></a>    result_heatmap <span class="op">=</span> pd.DataFrame(index<span class="op">=</span>np.arange(<span class="dv">6</span>)</span>
<span id="cb25-275"><a href="#cb25-275" aria-hidden="true" tabindex="-1"></a>                                 ,columns<span class="op">=</span>np.arange(<span class="dv">6</span>)</span>
<span id="cb25-276"><a href="#cb25-276" aria-hidden="true" tabindex="-1"></a>                                 ,data<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb25-277"><a href="#cb25-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-278"><a href="#cb25-278" aria-hidden="true" tabindex="-1"></a>    <span class="co">#実際のラベルに対する予測された回数をカウント</span></span>
<span id="cb25-279"><a href="#cb25-279" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> result_max_epochs.index:</span>
<span id="cb25-280"><a href="#cb25-280" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> result_max_epochs.at[i,<span class="st">'pred'</span>]</span>
<span id="cb25-281"><a href="#cb25-281" aria-hidden="true" tabindex="-1"></a>        a <span class="op">=</span> result_max_epochs.at[i,<span class="st">'acctual'</span>]</span>
<span id="cb25-282"><a href="#cb25-282" aria-hidden="true" tabindex="-1"></a>        result_heatmap.at[p,a] <span class="op">+=</span><span class="dv">1</span></span>
<span id="cb25-283"><a href="#cb25-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-284"><a href="#cb25-284" aria-hidden="true" tabindex="-1"></a>    <span class="co">#列相対度数に変換</span></span>
<span id="cb25-285"><a href="#cb25-285" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> c <span class="kw">in</span> result_heatmap:</span>
<span id="cb25-286"><a href="#cb25-286" aria-hidden="true" tabindex="-1"></a>        result_heatmap[c] <span class="op">=</span> result_heatmap[c] <span class="op">/</span> result_heatmap[c].<span class="bu">sum</span>()</span>
<span id="cb25-287"><a href="#cb25-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-288"><a href="#cb25-288" aria-hidden="true" tabindex="-1"></a>    <span class="co">#ヒートマップとして表現</span></span>
<span id="cb25-289"><a href="#cb25-289" aria-hidden="true" tabindex="-1"></a>    sns.heatmap(result_heatmap</span>
<span id="cb25-290"><a href="#cb25-290" aria-hidden="true" tabindex="-1"></a>               ,annot<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-291"><a href="#cb25-291" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'pred'</span>)</span>
<span id="cb25-292"><a href="#cb25-292" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'acctual'</span>)</span>
<span id="cb25-293"><a href="#cb25-293" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="st">'data/result/pred_acctual_heatmap.png'</span>)</span>
<span id="cb25-294"><a href="#cb25-294" aria-hidden="true" tabindex="-1"></a>    plt.close()</span>
<span id="cb25-295"><a href="#cb25-295" aria-hidden="true" tabindex="-1"></a>    results_df.to_csv(<span class="st">'data/result/pred_acctual.csv'</span></span>
<span id="cb25-296"><a href="#cb25-296" aria-hidden="true" tabindex="-1"></a>                     ,encoding<span class="op">=</span><span class="st">'utf_8_sig'</span>)</span>
<span id="cb25-297"><a href="#cb25-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-298"><a href="#cb25-298" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 特徴量を取得する</span></span>
<span id="cb25-299"><a href="#cb25-299" aria-hidden="true" tabindex="-1"></a>    train_features, train_labels <span class="op">=</span> extract_features(model, dataloaders[<span class="st">'train'</span>], device)</span>
<span id="cb25-300"><a href="#cb25-300" aria-hidden="true" tabindex="-1"></a>    val_features, val_labels <span class="op">=</span> extract_features(model, dataloaders[<span class="st">'val'</span>], device)</span>
<span id="cb25-301"><a href="#cb25-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-302"><a href="#cb25-302" aria-hidden="true" tabindex="-1"></a>    <span class="co"># (毎回学習するのは大変なので)特徴量を表示または保存しておく</span></span>
<span id="cb25-303"><a href="#cb25-303" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 読み込む場合は</span></span>
<span id="cb25-304"><a href="#cb25-304" aria-hidden="true" tabindex="-1"></a>    <span class="co"># train_features, train_labels = torch.load('train_features.pth')</span></span>
<span id="cb25-305"><a href="#cb25-305" aria-hidden="true" tabindex="-1"></a>    torch.save((train_features, train_labels), <span class="st">'data/result/convnext_train_features.pth'</span>)</span>
<span id="cb25-306"><a href="#cb25-306" aria-hidden="true" tabindex="-1"></a>    torch.save((val_features, val_labels), <span class="st">'data/result/convnext_val_features.pth'</span>)</span>
<span id="cb25-307"><a href="#cb25-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-308"><a href="#cb25-308" aria-hidden="true" tabindex="-1"></a>    <span class="co">#散布図の描画</span></span>
<span id="cb25-309"><a href="#cb25-309" aria-hidden="true" tabindex="-1"></a>    plot_tsne(train_features, train_labels,<span class="st">'data/result/convnext_tsne.png'</span>)</span>
<span id="cb25-310"><a href="#cb25-310" aria-hidden="true" tabindex="-1"></a>    plot_pca(train_features, train_labels,<span class="st">'data/result/convnext_pca.png'</span>)</span>
<span id="cb25-311"><a href="#cb25-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-312"><a href="#cb25-312" aria-hidden="true" tabindex="-1"></a><span class="co">#スクリプトとして実行された場合(python convnext.py)で実行された場合に,</span></span>
<span id="cb25-313"><a href="#cb25-313" aria-hidden="true" tabindex="-1"></a><span class="co"># if __name__ == '__main__': 以下のみが実行される.</span></span>
<span id="cb25-314"><a href="#cb25-314" aria-hidden="true" tabindex="-1"></a><span class="co"># 並列処理(multiprocessing)を行う場合にこのようにしないと,</span></span>
<span id="cb25-315"><a href="#cb25-315" aria-hidden="true" tabindex="-1"></a><span class="co"># 各処理ですべて同じコードが実行されるため,無限ループなどが起きる.</span></span>
<span id="cb25-316"><a href="#cb25-316" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">'__main__'</span>:</span>
<span id="cb25-317"><a href="#cb25-317" aria-hidden="true" tabindex="-1"></a>    main()</span></code></pre></div>
<p>出力されている<code>convnext_loss.png</code>と<code>convnext_acc.png</code>は<code>epoch</code>ごとの<code>loss</code>と<code>acc</code>の推移を表しています. <code>acc</code>は,モデルが予測したラベルの実際のラベルに対する正答率であり,<code>1</code>であれば予測が完全にラベルと一致していることを示しています. 今回は10代から60代までの6ラベルなので,完全にランダムにラベルを予測しても<code>0.16</code>程度はラベルと予測が一致します.</p>
<figure>
<img src="../images/convnext_loss_epoch20.png" alt="lossの推移" />
<figcaption aria-hidden="true">lossの推移</figcaption>
</figure>
<figure>
<img src="../images/convnext_acc_epoch20.png" alt="accの推移" />
<figcaption aria-hidden="true">accの推移</figcaption>
</figure>
<p>グラフを確認してみると<code>epoch</code>が<code>5</code>をピークとして<code>loss</code>も<code>acc</code>も低下していることがわかります. そこで, もう一度,<code>num_epochs</code>を<code>5</code>に変更して,学習してみましょう. <code>random_seed</code>が固定されているので,基本的には同じ値が出力されるはずです.</p>
<figure>
<img src="../images/convnext_acc_epoch5.png" alt="accの推移(epoch 5)" />
<figcaption aria-hidden="true">accの推移(epoch 5)</figcaption>
</figure>
<p>最終的に今回は, テストデータでの正答率が,<code>0.4</code>程度になりました. それほど高い値ではありませんが,ランダムに選択するよりはかなり良い値になったので,今回はこのくらいで良しとします. 実際の研究などでは,データ数を増やす,ハイパーパラメータやアルゴリズムを変更するなどして,もう少し良い値を目指したほうが良いでしょう.</p>
<p>出力されている<code>pred_acctual_heatmap.png</code>は, テストデータにおける実際のラベルに対する予測値を予測値のラベル毎にカウントしたものを相対度数として表現したヒートマップです.すべて正確に予測されていた場合,度数は対角線上に集中します.
このように可視化することで,モデルが何をどのように予測しているのかを確認できます.</p>
<figure>
<img src="../images/pred_acctual_heatmap.png" alt="accの推移(epoch 5)" />
<figcaption aria-hidden="true">accの推移(epoch 5)</figcaption>
</figure>
<p>ヒートマップを確認すると概ね対角線上に度数が集中していることがわかります. 特に10,20代(y軸の0,1)を50,60代と予測した数は0であり,年齢が離れるほど正確に識別されていることがわかります.</p>
<p>一方で,実際のラベルが10,20,40代であるときに,30代であると誤って予測する確率が高く,30代以前はあまり上手く識別できないことがわかります.</p>
<p>続いて,<code>PCA</code>と<code>t-sne</code>の結果を確認してみましょう.</p>
<figure>
<img src="../images/convnext_pca.png" alt="PCA" />
<figcaption aria-hidden="true">PCA</figcaption>
</figure>
<figure>
<img src="../images/convnext_tsne.png" alt="t-sne" />
<figcaption aria-hidden="true">t-sne</figcaption>
</figure>
<p>いずれも左から右に行くにつれて,年齢が高くなっており,ある程度識別できていることがわかります.一方で,30代の緑色が広い範囲に分布しているために識別が困難であること,50代と60代が左右とは別の特徴量で識別されていることなどがわかります.</p>
<p>このように,学習されたモデルの特徴量を分析することで,それぞれのクラスの特徴がある程度見えてきます.</p>
<p>それぞれの横軸,縦軸の特徴量が実際には何であるかは,各学習層でどのような特徴を抽出しているかを<strong>特徴マップ</strong>などによって可視化することが可能ですが,今回は扱いません. 興味がある方は,教員に聞いてみましょう.</p>
<p>yakagika</p>


<!-- 前後の章へのナビゲーション -->
<div class="chapter-navigation">
    <nav>
        
            <a class="nav-link prev" href="slds13.html">← Previous Chapter</a>
        
        
            <a class="nav-link next" href="slds15.html">Next Chapter →</a>
        
    </nav>
</div>

    <div style="clear: both"></div>

    <div id="footer">
        Site proudly generated by
        <a href="http://jaspervdj.be/hakyll">Hakyll</a>.
    </div>
</div>

        <!-- GUID -->
        <div style="display: none">ce0f13b2-4a83-4c1c-b2b9-b6d18f4ee6d2</div>

        
        <!-- KaTeX JavaScript and auto-render extension -->
        <script>
          document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
              delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "\[", right: "\]", display: true},
                {left: "$", right: "$", display: false} // インライン数式用のデリミタを追加
              ]
            });
          });
        </script>
        
    </body>

</html>
